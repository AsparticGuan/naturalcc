nohup: ignoring input
[2021-04-04 11:12:14]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/completion/gpt2/config/csn_feng/java.yml (train.py:291, cli_main())
[2021-04-04 11:12:14]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:293, cli_main())
[2021-04-04 11:12:16]    INFO >> distributed init (rank 1): tcp://localhost:15653 (distributed_utils.py:84, distributed_init())
[2021-04-04 11:12:16]    INFO >> distributed init (rank 0): tcp://localhost:15653 (distributed_utils.py:84, distributed_init())
[2021-04-04 11:12:16]    INFO >> distributed init (rank 2): tcp://localhost:15653 (distributed_utils.py:84, distributed_init())
[2021-04-04 11:12:16]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 11:12:16]    INFO >> distributed init (rank 3): tcp://localhost:15653 (distributed_utils.py:84, distributed_init())
[2021-04-04 11:12:16]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 11:12:17]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 11:12:17]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 11:12:17]    INFO >> initialized host node14 as rank 0 (distributed_utils.py:93, distributed_init())
[2021-04-04 11:12:17]    INFO >> initialized host node14 as rank 3 (distributed_utils.py:93, distributed_init())
[2021-04-04 11:12:17]    INFO >> initialized host node14 as rank 1 (distributed_utils.py:93, distributed_init())
[2021-04-04 11:12:17]    INFO >> initialized host node14 as rank 2 (distributed_utils.py:93, distributed_init())
[2021-04-04 11:12:22]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15653', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:201, single_main())
[2021-04-04 11:12:22]    INFO >> [code_tokens] dictionary: 50000 types (completion.py:101, setup_task())
[2021-04-04 11:12:22]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 11:12:22]    INFO >> loaded 5183 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/valid.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 11:12:23]    INFO >> GPT2(
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50000, 300, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (1): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (2): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (3): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (4): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (5): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
    )
    (out_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
  )
) (train.py:212, single_main())
[2021-04-04 11:12:23]    INFO >> model completion_gpt2, criterion CompletionCrossEntropyCriterion (train.py:213, single_main())
[2021-04-04 11:12:23]    INFO >> num. model params: 23076864 (num. trained: 23076864) (train.py:214, single_main())
[2021-04-04 11:12:23]    INFO >> training on 4 GPUs (train.py:221, single_main())
[2021-04-04 11:12:23]    INFO >> max tokens per GPU = 100000.0 and max sentences per GPU = 32 (train.py:222, single_main())
[2021-04-04 11:12:23]    INFO >> no existing checkpoint found checkpoint_best.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-04 11:12:23]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-04-04 11:12:23]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 11:12:23]    INFO >> loaded 164923 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/train.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 11:12:24]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 11:15:05]    INFO >> epoch 001:    500 / 1289 loss=4.206, accuracy=0, mrr=0, ppl=18.45, wps=40626.5, ups=3.24, wpb=12525.3, bsz=128, num_updates=500, lr=0.001, gnorm=0.95, clip=0, train_wall=154, wall=161 (progress_bar.py:260, log())
[2021-04-04 11:17:35]    INFO >> epoch 001:   1000 / 1289 loss=2.828, accuracy=0, mrr=0, ppl=7.1, wps=41569.5, ups=3.32, wpb=12513.2, bsz=128, num_updates=1000, lr=0.001, gnorm=0.669, clip=0, train_wall=149, wall=312 (progress_bar.py:260, log())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 11:19:02]    INFO >> epoch 001 | loss 3.276 | accuracy 0 | mrr 0 | ppl 9.69 | wps 41171 | ups 3.29 | wpb 12498 | bsz 127.9 | num_updates 1289 | lr 0.001 | gnorm 0.766 | clip 0 | train_wall 388 | wall 398 (progress_bar.py:269, print())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 11:19:19]    INFO >> epoch 001 | valid on 'valid' subset | loss 2.437 | accuracy 0.629736 | mrr 0.733836 | ppl 5.41 | wps 39645.5 | wpb 21641.3 | bsz 246.8 | num_updates 1289 (progress_bar.py:269, print())
[2021-04-04 11:19:20]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 1 @ 1289 updates, score 0.733836) (writing took 0.965029 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 11:20:28]    INFO >> epoch 002:    211 / 1289 loss=2.365, accuracy=0, mrr=0, ppl=5.15, wps=35905.7, ups=2.88, wpb=12445.9, bsz=127.9, num_updates=1500, lr=0.001, gnorm=0.598, clip=0, train_wall=148, wall=485 (progress_bar.py:260, log())
[2021-04-04 11:22:59]    INFO >> epoch 002:    711 / 1289 loss=2.088, accuracy=0, mrr=0, ppl=4.25, wps=41591.7, ups=3.32, wpb=12534.1, bsz=128, num_updates=2000, lr=0.001, gnorm=0.534, clip=0, train_wall=150, wall=636 (progress_bar.py:260, log())
[2021-04-04 11:25:28]    INFO >> epoch 002:   1211 / 1289 loss=1.937, accuracy=0, mrr=0, ppl=3.83, wps=42000.3, ups=3.36, wpb=12492, bsz=128, num_updates=2500, lr=0.001, gnorm=0.52, clip=0, train_wall=148, wall=785 (progress_bar.py:260, log())
[2021-04-04 11:25:52]    INFO >> epoch 002 | loss 2.046 | accuracy 0 | mrr 0 | ppl 4.13 | wps 39246 | ups 3.14 | wpb 12498 | bsz 127.9 | num_updates 2578 | lr 0.001 | gnorm 0.532 | clip 0 | train_wall 383 | wall 809 (progress_bar.py:269, print())
[2021-04-04 11:26:06]    INFO >> epoch 002 | valid on 'valid' subset | loss 2.092 | accuracy 0.671207 | mrr 0.767334 | ppl 4.26 | wps 56081.1 | wpb 21641.3 | bsz 246.8 | num_updates 2578 | best_mrr 0.767334 (progress_bar.py:269, print())
[2021-04-04 11:26:20]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 2 @ 2578 updates, score 0.767334) (writing took 14.242375 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 11:28:31]    INFO >> epoch 003:    422 / 1289 loss=1.831, accuracy=0, mrr=0, ppl=3.56, wps=34092.4, ups=2.72, wpb=12511.6, bsz=127.9, num_updates=3000, lr=0.001, gnorm=0.466, clip=0, train_wall=148, wall=968 (progress_bar.py:260, log())
[2021-04-04 11:31:02]    INFO >> epoch 003:    922 / 1289 loss=1.746, accuracy=0, mrr=0, ppl=3.35, wps=41415.5, ups=3.31, wpb=12516.8, bsz=128, num_updates=3500, lr=0.001, gnorm=0.426, clip=0, train_wall=150, wall=1119 (progress_bar.py:260, log())
[2021-04-04 11:32:52]    INFO >> epoch 003 | loss 1.758 | accuracy 0 | mrr 0 | ppl 3.38 | wps 38397 | ups 3.07 | wpb 12498 | bsz 127.9 | num_updates 3867 | lr 0.001 | gnorm 0.436 | clip 0 | train_wall 382 | wall 1229 (progress_bar.py:269, print())
[2021-04-04 11:33:06]    INFO >> epoch 003 | valid on 'valid' subset | loss 2.086 | accuracy 0.669625 | mrr 0.767105 | ppl 4.25 | wps 56096.2 | wpb 21641.3 | bsz 246.8 | num_updates 3867 | best_mrr 0.767334 (progress_bar.py:269, print())
[2021-04-04 11:33:13]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_last.pt (epoch 3 @ 3867 updates, score 0.767105) (writing took 7.940781 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 11:33:59]    INFO >> epoch 004:    133 / 1289 loss=1.736, accuracy=0, mrr=0, ppl=3.33, wps=35196.1, ups=2.83, wpb=12448.8, bsz=127.9, num_updates=4000, lr=0.001, gnorm=0.487, clip=0, train_wall=147, wall=1296 (progress_bar.py:260, log())
[2021-04-04 11:36:29]    INFO >> epoch 004:    633 / 1289 loss=1.654, accuracy=0, mrr=0, ppl=3.15, wps=41787.8, ups=3.34, wpb=12513.8, bsz=128, num_updates=4500, lr=0.001, gnorm=0.408, clip=0, train_wall=149, wall=1446 (progress_bar.py:260, log())
[2021-04-04 11:38:58]    INFO >> epoch 004:   1133 / 1289 loss=1.602, accuracy=0, mrr=0, ppl=3.04, wps=41950.8, ups=3.36, wpb=12503.6, bsz=128, num_updates=5000, lr=0.001, gnorm=0.4, clip=0, train_wall=148, wall=1595 (progress_bar.py:260, log())
[2021-04-04 11:39:45]    INFO >> epoch 004 | loss 1.645 | accuracy 0 | mrr 0 | ppl 3.13 | wps 38955.3 | ups 3.12 | wpb 12498 | bsz 127.9 | num_updates 5156 | lr 0.001 | gnorm 0.43 | clip 0 | train_wall 383 | wall 1642 (progress_bar.py:269, print())
[2021-04-04 11:39:59]    INFO >> epoch 004 | valid on 'valid' subset | loss 2.002 | accuracy 0.684114 | mrr 0.777022 | ppl 4.01 | wps 55633.8 | wpb 21641.3 | bsz 246.8 | num_updates 5156 | best_mrr 0.777022 (progress_bar.py:269, print())
[2021-04-04 11:40:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 4 @ 5156 updates, score 0.777022) (writing took 14.360481 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 11:42:01]    INFO >> epoch 005:    344 / 1289 loss=1.578, accuracy=0, mrr=0, ppl=2.99, wps=34086.2, ups=2.73, wpb=12494.2, bsz=127.9, num_updates=5500, lr=0.001, gnorm=0.381, clip=0, train_wall=147, wall=1778 (progress_bar.py:260, log())
[2021-04-04 11:44:32]    INFO >> epoch 005:    844 / 1289 loss=1.537, accuracy=0, mrr=0, ppl=2.9, wps=41573.5, ups=3.32, wpb=12528.6, bsz=128, num_updates=6000, lr=0.001, gnorm=0.378, clip=0, train_wall=150, wall=1929 (progress_bar.py:260, log())
[2021-04-04 11:46:45]    INFO >> epoch 005 | loss 1.539 | accuracy 0 | mrr 0 | ppl 2.91 | wps 38381.7 | ups 3.07 | wpb 12498 | bsz 127.9 | num_updates 6445 | lr 0.001 | gnorm 0.381 | clip 0 | train_wall 382 | wall 2062 (progress_bar.py:269, print())
[2021-04-04 11:46:59]    INFO >> epoch 005 | valid on 'valid' subset | loss 1.999 | accuracy 0.685877 | mrr 0.778098 | ppl 4 | wps 55213 | wpb 21641.3 | bsz 246.8 | num_updates 6445 | best_mrr 0.778098 (progress_bar.py:269, print())
[2021-04-04 11:47:13]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 5 @ 6445 updates, score 0.778098) (writing took 14.492580 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 11:47:36]    INFO >> epoch 006:     55 / 1289 loss=1.51, accuracy=0, mrr=0, ppl=2.85, wps=33804.5, ups=2.72, wpb=12441.5, bsz=127.9, num_updates=6500, lr=0.001, gnorm=0.384, clip=0, train_wall=148, wall=2113 (progress_bar.py:260, log())
[2021-04-04 11:50:05]    INFO >> epoch 006:    555 / 1289 loss=1.468, accuracy=0, mrr=0, ppl=2.77, wps=42146, ups=3.36, wpb=12534.8, bsz=128, num_updates=7000, lr=0.001, gnorm=0.343, clip=0, train_wall=148, wall=2261 (progress_bar.py:260, log())
[2021-04-04 11:52:34]    INFO >> epoch 006:   1055 / 1289 loss=1.491, accuracy=0, mrr=0, ppl=2.81, wps=41850.5, ups=3.34, wpb=12523.5, bsz=128, num_updates=7500, lr=0.001, gnorm=0.343, clip=0, train_wall=148, wall=2411 (progress_bar.py:260, log())
[2021-04-04 11:53:44]    INFO >> epoch 006 | loss 1.481 | accuracy 0 | mrr 0 | ppl 2.79 | wps 38450.8 | ups 3.08 | wpb 12498 | bsz 127.9 | num_updates 7734 | lr 0.001 | gnorm 0.343 | clip 0 | train_wall 381 | wall 2481 (progress_bar.py:269, print())
[2021-04-04 11:53:58]    INFO >> epoch 006 | valid on 'valid' subset | loss 1.941 | accuracy 0.694874 | mrr 0.785115 | ppl 3.84 | wps 57003.8 | wpb 21641.3 | bsz 246.8 | num_updates 7734 | best_mrr 0.785115 (progress_bar.py:269, print())
[2021-04-04 11:54:12]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 6 @ 7734 updates, score 0.785115) (writing took 14.278914 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 11:55:37]    INFO >> epoch 007:    266 / 1289 loss=1.434, accuracy=0, mrr=0, ppl=2.7, wps=34098.1, ups=2.74, wpb=12445.9, bsz=127.9, num_updates=8000, lr=0.001, gnorm=0.335, clip=0, train_wall=147, wall=2594 (progress_bar.py:260, log())
[2021-04-04 11:58:05]    INFO >> epoch 007:    766 / 1289 loss=1.415, accuracy=0, mrr=0, ppl=2.67, wps=42141.7, ups=3.37, wpb=12488.7, bsz=128, num_updates=8500, lr=0.001, gnorm=0.333, clip=0, train_wall=147, wall=2742 (progress_bar.py:260, log())
[2021-04-04 12:00:34]    INFO >> epoch 007:   1266 / 1289 loss=1.429, accuracy=0, mrr=0, ppl=2.69, wps=42090.2, ups=3.36, wpb=12508.6, bsz=128, num_updates=9000, lr=0.001, gnorm=0.329, clip=0, train_wall=147, wall=2890 (progress_bar.py:260, log())
[2021-04-04 12:00:41]    INFO >> epoch 007 | loss 1.414 | accuracy 0 | mrr 0 | ppl 2.67 | wps 38607.3 | ups 3.09 | wpb 12498 | bsz 127.9 | num_updates 9023 | lr 0.001 | gnorm 0.331 | clip 0 | train_wall 380 | wall 2898 (progress_bar.py:269, print())
[2021-04-04 12:00:55]    INFO >> epoch 007 | valid on 'valid' subset | loss 1.934 | accuracy 0.69729 | mrr 0.786898 | ppl 3.82 | wps 56666.6 | wpb 21641.3 | bsz 246.8 | num_updates 9023 | best_mrr 0.786898 (progress_bar.py:269, print())
[2021-04-04 12:01:10]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 7 @ 9023 updates, score 0.786898) (writing took 14.527830 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:03:38]    INFO >> epoch 008:    477 / 1289 loss=1.338, accuracy=0, mrr=0, ppl=2.53, wps=33793.4, ups=2.71, wpb=12474.6, bsz=127.9, num_updates=9500, lr=0.001, gnorm=0.325, clip=0, train_wall=149, wall=3075 (progress_bar.py:260, log())
[2021-04-04 12:06:06]    INFO >> epoch 008:    977 / 1289 loss=1.371, accuracy=0, mrr=0, ppl=2.59, wps=42428.8, ups=3.39, wpb=12512, bsz=128, num_updates=10000, lr=0.001, gnorm=0.322, clip=0, train_wall=146, wall=3222 (progress_bar.py:260, log())
[2021-04-04 12:07:39]    INFO >> epoch 008 | loss 1.36 | accuracy 0 | mrr 0 | ppl 2.57 | wps 38556.5 | ups 3.09 | wpb 12498 | bsz 127.9 | num_updates 10312 | lr 0.001 | gnorm 0.321 | clip 0 | train_wall 380 | wall 3316 (progress_bar.py:269, print())
[2021-04-04 12:07:53]    INFO >> epoch 008 | valid on 'valid' subset | loss 1.942 | accuracy 0.697765 | mrr 0.78704 | ppl 3.84 | wps 56891.3 | wpb 21641.3 | bsz 246.8 | num_updates 10312 | best_mrr 0.78704 (progress_bar.py:269, print())
[2021-04-04 12:08:07]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_best.pt (epoch 8 @ 10312 updates, score 0.78704) (writing took 14.190910 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:09:08]    INFO >> epoch 009:    188 / 1289 loss=1.342, accuracy=0, mrr=0, ppl=2.54, wps=34158.2, ups=2.74, wpb=12466.6, bsz=127.9, num_updates=10500, lr=0.001, gnorm=0.314, clip=0, train_wall=147, wall=3405 (progress_bar.py:260, log())
[2021-04-04 12:11:36]    INFO >> epoch 009:    688 / 1289 loss=1.306, accuracy=0, mrr=0, ppl=2.47, wps=42206.9, ups=3.38, wpb=12501, bsz=128, num_updates=11000, lr=0.001, gnorm=0.318, clip=0, train_wall=147, wall=3553 (progress_bar.py:260, log())
[2021-04-04 12:14:05]    INFO >> epoch 009:   1188 / 1289 loss=1.329, accuracy=0, mrr=0, ppl=2.51, wps=41881, ups=3.35, wpb=12506.1, bsz=128, num_updates=11500, lr=0.001, gnorm=0.31, clip=0, train_wall=148, wall=3702 (progress_bar.py:260, log())
[2021-04-04 12:14:36]    INFO >> epoch 009 | loss 1.312 | accuracy 0 | mrr 0 | ppl 2.48 | wps 38611.1 | ups 3.09 | wpb 12498 | bsz 127.9 | num_updates 11601 | lr 0.001 | gnorm 0.315 | clip 0 | train_wall 380 | wall 3733 (progress_bar.py:269, print())
[2021-04-04 12:14:50]    INFO >> epoch 009 | valid on 'valid' subset | loss 1.976 | accuracy 0.697112 | mrr 0.786008 | ppl 3.93 | wps 56096.7 | wpb 21641.3 | bsz 246.8 | num_updates 11601 | best_mrr 0.78704 (progress_bar.py:269, print())
[2021-04-04 12:14:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_last.pt (epoch 9 @ 11601 updates, score 0.786008) (writing took 7.712762 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:17:03]    INFO >> epoch 010:    399 / 1289 loss=1.261, accuracy=0, mrr=0, ppl=2.4, wps=35188.8, ups=2.81, wpb=12521.6, bsz=127.9, num_updates=12000, lr=0.001, gnorm=0.315, clip=0, train_wall=149, wall=3880 (progress_bar.py:260, log())
[2021-04-04 12:19:33]    INFO >> epoch 010:    899 / 1289 loss=1.272, accuracy=0, mrr=0, ppl=2.41, wps=41881.8, ups=3.35, wpb=12519.5, bsz=128, num_updates=12500, lr=0.001, gnorm=0.311, clip=0, train_wall=148, wall=4030 (progress_bar.py:260, log())
[2021-04-04 12:21:31]    INFO >> epoch 010 | loss 1.268 | accuracy 0 | mrr 0 | ppl 2.41 | wps 38813.2 | ups 3.11 | wpb 12498 | bsz 127.9 | num_updates 12890 | lr 0.001 | gnorm 0.311 | clip 0 | train_wall 384 | wall 4148 (progress_bar.py:269, print())
[2021-04-04 12:21:46]    INFO >> epoch 010 | valid on 'valid' subset | loss 2 | accuracy 0.696399 | mrr 0.784959 | ppl 4 | wps 52644 | wpb 21641.3 | bsz 246.8 | num_updates 12890 | best_mrr 0.78704 (progress_bar.py:269, print())
[2021-04-04 12:21:53]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_last.pt (epoch 10 @ 12890 updates, score 0.784959) (writing took 7.163092 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:22:32]    INFO >> epoch 011:    110 / 1289 loss=1.267, accuracy=0, mrr=0, ppl=2.41, wps=34901.3, ups=2.79, wpb=12504.1, bsz=127.9, num_updates=13000, lr=0.001, gnorm=0.309, clip=0, train_wall=150, wall=4209 (progress_bar.py:260, log())
[2021-04-04 12:25:00]    INFO >> epoch 011:    610 / 1289 loss=1.213, accuracy=0, mrr=0, ppl=2.32, wps=42099.1, ups=3.37, wpb=12495.1, bsz=128, num_updates=13500, lr=0.001, gnorm=0.314, clip=0, train_wall=147, wall=4357 (progress_bar.py:260, log())
[2021-04-04 12:27:31]    INFO >> epoch 011:   1110 / 1289 loss=1.243, accuracy=0, mrr=0, ppl=2.37, wps=41244, ups=3.32, wpb=12441.6, bsz=128, num_updates=14000, lr=0.001, gnorm=0.308, clip=0, train_wall=150, wall=4508 (progress_bar.py:260, log())
[2021-04-04 12:28:25]    INFO >> epoch 011 | loss 1.228 | accuracy 0 | mrr 0 | ppl 2.34 | wps 38939 | ups 3.12 | wpb 12498 | bsz 127.9 | num_updates 14179 | lr 0.001 | gnorm 0.31 | clip 0 | train_wall 383 | wall 4562 (progress_bar.py:269, print())
[2021-04-04 12:28:39]    INFO >> epoch 011 | valid on 'valid' subset | loss 2.021 | accuracy 0.694713 | mrr 0.783771 | ppl 4.06 | wps 55562.9 | wpb 21641.3 | bsz 246.8 | num_updates 14179 | best_mrr 0.78704 (progress_bar.py:269, print())
[2021-04-04 12:28:47]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_last.pt (epoch 11 @ 14179 updates, score 0.783771) (writing took 7.866259 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:30:27]    INFO >> epoch 012:    321 / 1289 loss=1.189, accuracy=0, mrr=0, ppl=2.28, wps=35413.5, ups=2.84, wpb=12477.6, bsz=127.9, num_updates=14500, lr=0.001, gnorm=0.309, clip=0, train_wall=147, wall=4684 (progress_bar.py:260, log())
[2021-04-04 12:32:57]    INFO >> epoch 012:    821 / 1289 loss=1.19, accuracy=0, mrr=0, ppl=2.28, wps=41869.5, ups=3.34, wpb=12535.9, bsz=128, num_updates=15000, lr=0.001, gnorm=0.312, clip=0, train_wall=149, wall=4834 (progress_bar.py:260, log())
[2021-04-04 12:35:17]    INFO >> epoch 012 | loss 1.191 | accuracy 0 | mrr 0 | ppl 2.28 | wps 39084.9 | ups 3.13 | wpb 12498 | bsz 127.9 | num_updates 15468 | lr 0.001 | gnorm 0.309 | clip 0 | train_wall 381 | wall 4974 (progress_bar.py:269, print())
[2021-04-04 12:35:31]    INFO >> epoch 012 | valid on 'valid' subset | loss 2.044 | accuracy 0.694656 | mrr 0.783452 | ppl 4.12 | wps 55670.7 | wpb 21641.3 | bsz 246.8 | num_updates 15468 | best_mrr 0.78704 (progress_bar.py:269, print())
[2021-04-04 12:35:39]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_last.pt (epoch 12 @ 15468 updates, score 0.783452) (writing took 7.685250 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:35:54]    INFO >> epoch 013:     32 / 1289 loss=1.21, accuracy=0, mrr=0, ppl=2.31, wps=35442.8, ups=2.83, wpb=12533.8, bsz=127.9, num_updates=15500, lr=0.001, gnorm=0.303, clip=0, train_wall=148, wall=5011 (progress_bar.py:260, log())
[2021-04-04 12:38:24]    INFO >> epoch 013:    532 / 1289 loss=1.131, accuracy=0, mrr=0, ppl=2.19, wps=41467.3, ups=3.34, wpb=12428, bsz=128, num_updates=16000, lr=0.001, gnorm=0.313, clip=0, train_wall=149, wall=5161 (progress_bar.py:260, log())
[2021-04-04 12:40:53]    INFO >> epoch 013:   1032 / 1289 loss=1.167, accuracy=0, mrr=0, ppl=2.25, wps=42052.7, ups=3.35, wpb=12554.7, bsz=128, num_updates=16500, lr=0.001, gnorm=0.305, clip=0, train_wall=148, wall=5310 (progress_bar.py:260, log())
[2021-04-04 12:42:10]    INFO >> epoch 013 | loss 1.155 | accuracy 0 | mrr 0 | ppl 2.23 | wps 39016.2 | ups 3.12 | wpb 12498 | bsz 127.9 | num_updates 16757 | lr 0.001 | gnorm 0.307 | clip 0 | train_wall 382 | wall 5387 (progress_bar.py:269, print())
[2021-04-04 12:42:24]    INFO >> epoch 013 | valid on 'valid' subset | loss 2.076 | accuracy 0.693285 | mrr 0.782433 | ppl 4.22 | wps 55743.5 | wpb 21641.3 | bsz 246.8 | num_updates 16757 | best_mrr 0.78704 (progress_bar.py:269, print())
[2021-04-04 12:42:32]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/java/gpt2/checkpoints/checkpoint_last.pt (epoch 13 @ 16757 updates, score 0.782433) (writing took 7.945908 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 12:42:32]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:176, should_stop_early())
[2021-04-04 12:42:32]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:259, single_main())
[2021-04-04 12:42:32]    INFO >> done training in 5408.2 seconds (train.py:271, single_main())
