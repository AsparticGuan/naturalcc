nohup: ignoring input
[2021-04-04 06:21:53]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/completion/gpt2/config/csn_feng/php.yml (train.py:291, cli_main())
[2021-04-04 06:21:53]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:293, cli_main())
[2021-04-04 06:21:54]    INFO >> distributed init (rank 1): tcp://localhost:14991 (distributed_utils.py:84, distributed_init())
[2021-04-04 06:21:54]    INFO >> distributed init (rank 0): tcp://localhost:14991 (distributed_utils.py:84, distributed_init())
[2021-04-04 06:21:54]    INFO >> distributed init (rank 3): tcp://localhost:14991 (distributed_utils.py:84, distributed_init())
[2021-04-04 06:21:54]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 06:21:54]    INFO >> distributed init (rank 2): tcp://localhost:14991 (distributed_utils.py:84, distributed_init())
[2021-04-04 06:21:54]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 06:21:55]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 06:21:55]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 06:21:55]    INFO >> initialized host node14 as rank 0 (distributed_utils.py:93, distributed_init())
[2021-04-04 06:21:55]    INFO >> initialized host node14 as rank 1 (distributed_utils.py:93, distributed_init())
[2021-04-04 06:21:55]    INFO >> initialized host node14 as rank 3 (distributed_utils.py:93, distributed_init())
[2021-04-04 06:21:55]    INFO >> initialized host node14 as rank 2 (distributed_utils.py:93, distributed_init())
[2021-04-04 06:22:01]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14991', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:201, single_main())
[2021-04-04 06:22:01]    INFO >> [code_tokens] dictionary: 50000 types (completion.py:101, setup_task())
[2021-04-04 06:22:01]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 06:22:01]    INFO >> loaded 12982 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/valid.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 06:22:02]    INFO >> GPT2(
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50000, 300, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (1): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (2): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (3): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (4): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (5): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
    )
    (out_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
  )
) (train.py:212, single_main())
[2021-04-04 06:22:02]    INFO >> model completion_gpt2, criterion CompletionCrossEntropyCriterion (train.py:213, single_main())
[2021-04-04 06:22:02]    INFO >> num. model params: 23076864 (num. trained: 23076864) (train.py:214, single_main())
[2021-04-04 06:22:02]    INFO >> training on 4 GPUs (train.py:221, single_main())
[2021-04-04 06:22:02]    INFO >> max tokens per GPU = 100000.0 and max sentences per GPU = 32 (train.py:222, single_main())
[2021-04-04 06:22:02]    INFO >> no existing checkpoint found checkpoint_best.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-04 06:22:02]    INFO >> loading train data for epoch 1 (ncc_trainers.py:284, get_train_iterator())
[2021-04-04 06:22:02]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 06:22:02]    INFO >> loaded 241241 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/train.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 06:22:03]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 06:24:44]    INFO >> epoch 001:    500 / 1885 loss=3.662, accuracy=0, mrr=0, ppl=12.66, wps=43377.1, ups=3.24, wpb=13403.9, bsz=128, num_updates=500, lr=0.001, gnorm=0.921, clip=0, train_wall=154, wall=162 (progress_bar.py:260, log())
[2021-04-04 06:27:13]    INFO >> epoch 001:   1000 / 1885 loss=2.56, accuracy=0, mrr=0, ppl=5.9, wps=45023.5, ups=3.35, wpb=13436.6, bsz=128, num_updates=1000, lr=0.001, gnorm=0.664, clip=0, train_wall=148, wall=312 (progress_bar.py:260, log())
[2021-04-04 06:29:43]    INFO >> epoch 001:   1500 / 1885 loss=2.186, accuracy=0, mrr=0, ppl=4.55, wps=44879.5, ups=3.34, wpb=13435.5, bsz=128, num_updates=1500, lr=0.001, gnorm=0.55, clip=0, train_wall=149, wall=461 (progress_bar.py:260, log())
[2021-04-04 06:31:39]    INFO >> epoch 001 | loss 2.641 | accuracy 0 | mrr 0 | ppl 6.24 | wps 44448.9 | ups 3.31 | wpb 13428.8 | bsz 128 | num_updates 1885 | lr 0.001 | gnorm 0.67 | clip 0 | train_wall 566 | wall 577 (progress_bar.py:269, print())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 06:32:10]    INFO >> epoch 001 | valid on 'valid' subset | loss 1.998 | accuracy 0.686842 | mrr 0.779252 | ppl 3.99 | wps 57667 | wpb 27223.6 | bsz 254.5 | num_updates 1885 (progress_bar.py:269, print())
[2021-04-04 06:32:11]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 1 @ 1885 updates, score 0.779252) (writing took 0.966303 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:32:51]    INFO >> epoch 002:    115 / 1885 loss=1.999, accuracy=0, mrr=0, ppl=4, wps=35644.9, ups=2.66, wpb=13409.4, bsz=127.9, num_updates=2000, lr=0.001, gnorm=0.499, clip=0, train_wall=149, wall=649 (progress_bar.py:260, log())
[2021-04-04 06:35:21]    INFO >> epoch 002:    615 / 1885 loss=1.867, accuracy=0, mrr=0, ppl=3.65, wps=44852.6, ups=3.33, wpb=13449.1, bsz=128, num_updates=2500, lr=0.001, gnorm=0.46, clip=0, train_wall=149, wall=799 (progress_bar.py:260, log())
[2021-04-04 06:37:49]    INFO >> epoch 002:   1115 / 1885 loss=1.774, accuracy=0, mrr=0, ppl=3.42, wps=45204.9, ups=3.37, wpb=13405.5, bsz=128, num_updates=3000, lr=0.001, gnorm=0.432, clip=0, train_wall=147, wall=948 (progress_bar.py:260, log())
[2021-04-04 06:40:19]    INFO >> epoch 002:   1615 / 1885 loss=1.694, accuracy=0, mrr=0, ppl=3.24, wps=45126, ups=3.35, wpb=13465.2, bsz=128, num_updates=3500, lr=0.001, gnorm=0.387, clip=0, train_wall=148, wall=1097 (progress_bar.py:260, log())
[2021-04-04 06:41:41]    INFO >> epoch 002 | loss 1.772 | accuracy 0 | mrr 0 | ppl 3.41 | wps 42080.1 | ups 3.13 | wpb 13428.8 | bsz 128 | num_updates 3770 | lr 0.001 | gnorm 0.424 | clip 0 | train_wall 559 | wall 1179 (progress_bar.py:269, print())
[2021-04-04 06:42:06]    INFO >> epoch 002 | valid on 'valid' subset | loss 1.766 | accuracy 0.71533 | mrr 0.801837 | ppl 3.4 | wps 71349.9 | wpb 27223.6 | bsz 254.5 | num_updates 3770 | best_mrr 0.801837 (progress_bar.py:269, print())
[2021-04-04 06:42:21]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 2 @ 3770 updates, score 0.801837) (writing took 14.601106 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:43:35]    INFO >> epoch 003:    230 / 1885 loss=1.654, accuracy=0, mrr=0, ppl=3.15, wps=34102.7, ups=2.55, wpb=13395.5, bsz=127.9, num_updates=4000, lr=0.001, gnorm=0.377, clip=0, train_wall=149, wall=1293 (progress_bar.py:260, log())
[2021-04-04 06:46:04]    INFO >> epoch 003:    730 / 1885 loss=1.609, accuracy=0, mrr=0, ppl=3.05, wps=45103.5, ups=3.35, wpb=13454.7, bsz=128, num_updates=4500, lr=0.001, gnorm=0.354, clip=0, train_wall=148, wall=1442 (progress_bar.py:260, log())
[2021-04-04 06:48:32]    INFO >> epoch 003:   1230 / 1885 loss=1.571, accuracy=0, mrr=0, ppl=2.97, wps=45387.6, ups=3.38, wpb=13419.5, bsz=128, num_updates=5000, lr=0.001, gnorm=0.341, clip=0, train_wall=147, wall=1590 (progress_bar.py:260, log())
[2021-04-04 06:51:02]    INFO >> epoch 003:   1730 / 1885 loss=1.54, accuracy=0, mrr=0, ppl=2.91, wps=44916.5, ups=3.34, wpb=13457.3, bsz=128, num_updates=5500, lr=0.001, gnorm=0.329, clip=0, train_wall=149, wall=1740 (progress_bar.py:260, log())
[2021-04-04 06:51:49]    INFO >> epoch 003 | loss 1.578 | accuracy 0 | mrr 0 | ppl 2.99 | wps 41587.1 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 5655 | lr 0.001 | gnorm 0.343 | clip 0 | train_wall 558 | wall 1788 (progress_bar.py:269, print())
[2021-04-04 06:52:15]    INFO >> epoch 003 | valid on 'valid' subset | loss 1.694 | accuracy 0.725848 | mrr 0.809801 | ppl 3.24 | wps 70630.9 | wpb 27223.6 | bsz 254.5 | num_updates 5655 | best_mrr 0.809801 (progress_bar.py:269, print())
[2021-04-04 06:52:29]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 3 @ 5655 updates, score 0.809801) (writing took 14.591755 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:54:18]    INFO >> epoch 004:    345 / 1885 loss=1.518, accuracy=0, mrr=0, ppl=2.86, wps=34041.8, ups=2.54, wpb=13388.4, bsz=127.9, num_updates=6000, lr=0.001, gnorm=0.32, clip=0, train_wall=149, wall=1937 (progress_bar.py:260, log())
[2021-04-04 06:56:47]    INFO >> epoch 004:    845 / 1885 loss=1.495, accuracy=0, mrr=0, ppl=2.82, wps=45170.5, ups=3.36, wpb=13459.3, bsz=128, num_updates=6500, lr=0.001, gnorm=0.309, clip=0, train_wall=148, wall=2086 (progress_bar.py:260, log())
[2021-04-04 06:59:15]    INFO >> epoch 004:   1345 / 1885 loss=1.471, accuracy=0, mrr=0, ppl=2.77, wps=45443.5, ups=3.39, wpb=13392.9, bsz=128, num_updates=7000, lr=0.001, gnorm=0.306, clip=0, train_wall=146, wall=2233 (progress_bar.py:260, log())
[2021-04-04 07:01:46]    INFO >> epoch 004:   1845 / 1885 loss=1.451, accuracy=0, mrr=0, ppl=2.73, wps=44677.7, ups=3.31, wpb=13478.8, bsz=128, num_updates=7500, lr=0.001, gnorm=0.291, clip=0, train_wall=150, wall=2384 (progress_bar.py:260, log())
[2021-04-04 07:01:58]    INFO >> epoch 004 | loss 1.479 | accuracy 0 | mrr 0 | ppl 2.79 | wps 41577.9 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 7540 | lr 0.001 | gnorm 0.305 | clip 0 | train_wall 558 | wall 2396 (progress_bar.py:269, print())
[2021-04-04 07:02:24]    INFO >> epoch 004 | valid on 'valid' subset | loss 1.675 | accuracy 0.72911 | mrr 0.812329 | ppl 3.19 | wps 70558.5 | wpb 27223.6 | bsz 254.5 | num_updates 7540 | best_mrr 0.812329 (progress_bar.py:269, print())
[2021-04-04 07:02:38]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 4 @ 7540 updates, score 0.812329) (writing took 14.596572 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 07:05:01]    INFO >> epoch 005:    460 / 1885 loss=1.434, accuracy=0, mrr=0, ppl=2.7, wps=34223.1, ups=2.55, wpb=13403, bsz=127.9, num_updates=8000, lr=0.001, gnorm=0.291, clip=0, train_wall=148, wall=2580 (progress_bar.py:260, log())
[2021-04-04 07:07:30]    INFO >> epoch 005:    960 / 1885 loss=1.42, accuracy=0, mrr=0, ppl=2.68, wps=45094.5, ups=3.36, wpb=13424.3, bsz=128, num_updates=8500, lr=0.001, gnorm=0.284, clip=0, train_wall=148, wall=2728 (progress_bar.py:260, log())
[2021-04-04 07:09:58]    INFO >> epoch 005:   1460 / 1885 loss=1.402, accuracy=0, mrr=0, ppl=2.64, wps=45384.6, ups=3.38, wpb=13429, bsz=128, num_updates=9000, lr=0.001, gnorm=0.281, clip=0, train_wall=147, wall=2876 (progress_bar.py:260, log())
[2021-04-04 07:12:06]    INFO >> epoch 005 | loss 1.411 | accuracy 0 | mrr 0 | ppl 2.66 | wps 41633.5 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 9425 | lr 0.001 | gnorm 0.283 | clip 0 | train_wall 557 | wall 3004 (progress_bar.py:269, print())
[2021-04-04 07:12:31]    INFO >> epoch 005 | valid on 'valid' subset | loss 1.669 | accuracy 0.732007 | mrr 0.814253 | ppl 3.18 | wps 71414.4 | wpb 27223.6 | bsz 254.5 | num_updates 9425 | best_mrr 0.814253 (progress_bar.py:269, print())
[2021-04-04 07:12:46]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 5 @ 9425 updates, score 0.814253) (writing took 14.645021 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 07:13:14]    INFO >> epoch 006:     75 / 1885 loss=1.38, accuracy=0, mrr=0, ppl=2.6, wps=34313.1, ups=2.55, wpb=13435.7, bsz=127.9, num_updates=9500, lr=0.001, gnorm=0.273, clip=0, train_wall=148, wall=3072 (progress_bar.py:260, log())
[2021-04-04 07:15:43]    INFO >> epoch 006:    575 / 1885 loss=1.355, accuracy=0, mrr=0, ppl=2.56, wps=45260.7, ups=3.36, wpb=13465, bsz=128, num_updates=10000, lr=0.001, gnorm=0.256, clip=0, train_wall=148, wall=3221 (progress_bar.py:260, log())
[2021-04-04 07:18:12]    INFO >> epoch 006:   1075 / 1885 loss=1.364, accuracy=0, mrr=0, ppl=2.57, wps=45080, ups=3.35, wpb=13460.1, bsz=128, num_updates=10500, lr=0.001, gnorm=0.253, clip=0, train_wall=148, wall=3370 (progress_bar.py:260, log())
[2021-04-04 07:20:42]    INFO >> epoch 006:   1575 / 1885 loss=1.376, accuracy=0, mrr=0, ppl=2.6, wps=44801.2, ups=3.33, wpb=13434.8, bsz=128, num_updates=11000, lr=0.001, gnorm=0.25, clip=0, train_wall=149, wall=3520 (progress_bar.py:260, log())
[2021-04-04 07:22:15]    INFO >> epoch 006 | loss 1.365 | accuracy 0 | mrr 0 | ppl 2.58 | wps 41608.9 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 11310 | lr 0.001 | gnorm 0.252 | clip 0 | train_wall 558 | wall 3613 (progress_bar.py:269, print())
[2021-04-04 07:22:40]    INFO >> epoch 006 | valid on 'valid' subset | loss 1.62 | accuracy 0.737978 | mrr 0.81878 | ppl 3.07 | wps 70877.5 | wpb 27223.6 | bsz 254.5 | num_updates 11310 | best_mrr 0.81878 (progress_bar.py:269, print())
[2021-04-04 07:22:55]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 6 @ 11310 updates, score 0.81878) (writing took 14.777838 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 07:23:57]    INFO >> epoch 007:    190 / 1885 loss=1.339, accuracy=0, mrr=0, ppl=2.53, wps=34217.3, ups=2.56, wpb=13348.3, bsz=127.9, num_updates=11500, lr=0.001, gnorm=0.245, clip=0, train_wall=147, wall=3715 (progress_bar.py:260, log())
[2021-04-04 07:26:26]    INFO >> epoch 007:    690 / 1885 loss=1.304, accuracy=0, mrr=0, ppl=2.47, wps=45205.2, ups=3.36, wpb=13443.2, bsz=128, num_updates=12000, lr=0.001, gnorm=0.247, clip=0, train_wall=148, wall=3864 (progress_bar.py:260, log())
[2021-04-04 07:28:55]    INFO >> epoch 007:   1190 / 1885 loss=1.319, accuracy=0, mrr=0, ppl=2.5, wps=45173.1, ups=3.36, wpb=13454.9, bsz=128, num_updates=12500, lr=0.001, gnorm=0.24, clip=0, train_wall=148, wall=4013 (progress_bar.py:260, log())
[2021-04-04 07:31:24]    INFO >> epoch 007:   1690 / 1885 loss=1.325, accuracy=0, mrr=0, ppl=2.51, wps=44868.7, ups=3.35, wpb=13390.6, bsz=128, num_updates=13000, lr=0.001, gnorm=0.235, clip=0, train_wall=148, wall=4162 (progress_bar.py:260, log())
[2021-04-04 07:32:23]    INFO >> epoch 007 | loss 1.314 | accuracy 0 | mrr 0 | ppl 2.49 | wps 41608.1 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 13195 | lr 0.001 | gnorm 0.24 | clip 0 | train_wall 558 | wall 4221 (progress_bar.py:269, print())
[2021-04-04 07:32:48]    INFO >> epoch 007 | valid on 'valid' subset | loss 1.619 | accuracy 0.740357 | mrr 0.820305 | ppl 3.07 | wps 70994.3 | wpb 27223.6 | bsz 254.5 | num_updates 13195 | best_mrr 0.820305 (progress_bar.py:269, print())
[2021-04-04 07:33:03]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 7 @ 13195 updates, score 0.820305) (writing took 14.478643 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 07:34:39]    INFO >> epoch 008:    305 / 1885 loss=1.276, accuracy=0, mrr=0, ppl=2.42, wps=34511.3, ups=2.56, wpb=13484, bsz=127.9, num_updates=13500, lr=0.001, gnorm=0.235, clip=0, train_wall=148, wall=4357 (progress_bar.py:260, log())
[2021-04-04 07:37:10]    INFO >> epoch 008:    805 / 1885 loss=1.269, accuracy=0, mrr=0, ppl=2.41, wps=44677.6, ups=3.33, wpb=13434.8, bsz=128, num_updates=14000, lr=0.001, gnorm=0.237, clip=0, train_wall=149, wall=4508 (progress_bar.py:260, log())
[2021-04-04 07:39:38]    INFO >> epoch 008:   1305 / 1885 loss=1.28, accuracy=0, mrr=0, ppl=2.43, wps=45020.8, ups=3.36, wpb=13408.3, bsz=128, num_updates=14500, lr=0.001, gnorm=0.232, clip=0, train_wall=148, wall=4657 (progress_bar.py:260, log())
[2021-04-04 07:42:05]    INFO >> epoch 008:   1805 / 1885 loss=1.286, accuracy=0, mrr=0, ppl=2.44, wps=45645.5, ups=3.41, wpb=13397.9, bsz=128, num_updates=15000, lr=0.001, gnorm=0.226, clip=0, train_wall=146, wall=4803 (progress_bar.py:260, log())
[2021-04-04 07:42:30]    INFO >> epoch 008 | loss 1.273 | accuracy 0 | mrr 0 | ppl 2.42 | wps 41679.3 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 15080 | lr 0.001 | gnorm 0.233 | clip 0 | train_wall 557 | wall 4829 (progress_bar.py:269, print())
[2021-04-04 07:42:56]    INFO >> epoch 008 | valid on 'valid' subset | loss 1.626 | accuracy 0.740086 | mrr 0.820147 | ppl 3.09 | wps 71054.8 | wpb 27223.6 | bsz 254.5 | num_updates 15080 | best_mrr 0.820305 (progress_bar.py:269, print())
[2021-04-04 07:43:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 8 @ 15080 updates, score 0.820147) (writing took 7.947475 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 07:45:13]    INFO >> epoch 009:    420 / 1885 loss=1.224, accuracy=0, mrr=0, ppl=2.34, wps=35692.2, ups=2.66, wpb=13427.4, bsz=127.9, num_updates=15500, lr=0.001, gnorm=0.234, clip=0, train_wall=147, wall=4992 (progress_bar.py:260, log())
[2021-04-04 07:47:44]    INFO >> epoch 009:    920 / 1885 loss=1.231, accuracy=0, mrr=0, ppl=2.35, wps=44515.3, ups=3.32, wpb=13425.8, bsz=128, num_updates=16000, lr=0.001, gnorm=0.233, clip=0, train_wall=150, wall=5142 (progress_bar.py:260, log())
[2021-04-04 07:50:13]    INFO >> epoch 009:   1420 / 1885 loss=1.245, accuracy=0, mrr=0, ppl=2.37, wps=45109, ups=3.36, wpb=13430.3, bsz=128, num_updates=16500, lr=0.001, gnorm=0.228, clip=0, train_wall=148, wall=5291 (progress_bar.py:260, log())
[2021-04-04 07:52:31]    INFO >> epoch 009 | loss 1.237 | accuracy 0 | mrr 0 | ppl 2.36 | wps 42159.2 | ups 3.14 | wpb 13428.8 | bsz 128 | num_updates 16965 | lr 0.001 | gnorm 0.23 | clip 0 | train_wall 557 | wall 5429 (progress_bar.py:269, print())
[2021-04-04 07:52:56]    INFO >> epoch 009 | valid on 'valid' subset | loss 1.636 | accuracy 0.740406 | mrr 0.820013 | ppl 3.11 | wps 70773.5 | wpb 27223.6 | bsz 254.5 | num_updates 16965 | best_mrr 0.820305 (progress_bar.py:269, print())
[2021-04-04 07:53:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 9 @ 16965 updates, score 0.820013) (writing took 7.876499 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 07:53:20]    INFO >> epoch 010:     35 / 1885 loss=1.25, accuracy=0, mrr=0, ppl=2.38, wps=35886.4, ups=2.67, wpb=13443.9, bsz=127.9, num_updates=17000, lr=0.001, gnorm=0.225, clip=0, train_wall=147, wall=5479 (progress_bar.py:260, log())
[2021-04-04 07:55:48]    INFO >> epoch 010:    535 / 1885 loss=1.179, accuracy=0, mrr=0, ppl=2.26, wps=45483.9, ups=3.38, wpb=13453.3, bsz=128, num_updates=17500, lr=0.001, gnorm=0.232, clip=0, train_wall=147, wall=5626 (progress_bar.py:260, log())
[2021-04-04 07:58:17]    INFO >> epoch 010:   1035 / 1885 loss=1.202, accuracy=0, mrr=0, ppl=2.3, wps=45268.8, ups=3.36, wpb=13463.8, bsz=128, num_updates=18000, lr=0.001, gnorm=0.229, clip=0, train_wall=148, wall=5775 (progress_bar.py:260, log())
[2021-04-04 08:00:45]    INFO >> epoch 010:   1535 / 1885 loss=1.214, accuracy=0, mrr=0, ppl=2.32, wps=45107.9, ups=3.37, wpb=13397.2, bsz=128, num_updates=18500, lr=0.001, gnorm=0.224, clip=0, train_wall=147, wall=5924 (progress_bar.py:260, log())
[2021-04-04 08:02:29]    INFO >> epoch 010 | loss 1.203 | accuracy 0 | mrr 0 | ppl 2.3 | wps 42322 | ups 3.15 | wpb 13428.8 | bsz 128 | num_updates 18850 | lr 0.001 | gnorm 0.227 | clip 0 | train_wall 554 | wall 6027 (progress_bar.py:269, print())
[2021-04-04 08:02:54]    INFO >> epoch 010 | valid on 'valid' subset | loss 1.645 | accuracy 0.741009 | mrr 0.820601 | ppl 3.13 | wps 70414 | wpb 27223.6 | bsz 254.5 | num_updates 18850 | best_mrr 0.820601 (progress_bar.py:269, print())
[2021-04-04 08:03:09]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_best.pt (epoch 10 @ 18850 updates, score 0.820601) (writing took 14.779060 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 08:04:00]    INFO >> epoch 011:    150 / 1885 loss=1.199, accuracy=0, mrr=0, ppl=2.3, wps=34423, ups=2.57, wpb=13398.7, bsz=127.9, num_updates=19000, lr=0.001, gnorm=0.224, clip=0, train_wall=147, wall=6118 (progress_bar.py:260, log())
[2021-04-04 08:06:28]    INFO >> epoch 011:    650 / 1885 loss=1.155, accuracy=0, mrr=0, ppl=2.23, wps=45199.7, ups=3.37, wpb=13399.6, bsz=128, num_updates=19500, lr=0.001, gnorm=0.231, clip=0, train_wall=147, wall=6266 (progress_bar.py:260, log())
[2021-04-04 08:08:57]    INFO >> epoch 011:   1150 / 1885 loss=1.176, accuracy=0, mrr=0, ppl=2.26, wps=45140.2, ups=3.35, wpb=13463.2, bsz=128, num_updates=20000, lr=0.001, gnorm=0.226, clip=0, train_wall=148, wall=6416 (progress_bar.py:260, log())
[2021-04-04 08:11:26]    INFO >> epoch 011:   1650 / 1885 loss=1.191, accuracy=0, mrr=0, ppl=2.28, wps=44927.2, ups=3.35, wpb=13393.2, bsz=128, num_updates=20500, lr=0.001, gnorm=0.226, clip=0, train_wall=148, wall=6565 (progress_bar.py:260, log())
[2021-04-04 08:12:36]    INFO >> epoch 011 | loss 1.173 | accuracy 0 | mrr 0 | ppl 2.26 | wps 41653.3 | ups 3.1 | wpb 13428.8 | bsz 128 | num_updates 20735 | lr 0.001 | gnorm 0.227 | clip 0 | train_wall 557 | wall 6635 (progress_bar.py:269, print())
[2021-04-04 08:13:02]    INFO >> epoch 011 | valid on 'valid' subset | loss 1.668 | accuracy 0.739906 | mrr 0.819372 | ppl 3.18 | wps 70400.7 | wpb 27223.6 | bsz 254.5 | num_updates 20735 | best_mrr 0.820601 (progress_bar.py:269, print())
[2021-04-04 08:13:10]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 11 @ 20735 updates, score 0.819372) (writing took 8.014701 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 08:14:34]    INFO >> epoch 012:    265 / 1885 loss=1.145, accuracy=0, mrr=0, ppl=2.21, wps=35906.3, ups=2.67, wpb=13440.5, bsz=127.9, num_updates=21000, lr=0.001, gnorm=0.225, clip=0, train_wall=146, wall=6752 (progress_bar.py:260, log())
[2021-04-04 08:17:00]    INFO >> epoch 012:    765 / 1885 loss=1.133, accuracy=0, mrr=0, ppl=2.19, wps=45782.3, ups=3.41, wpb=13435.2, bsz=128, num_updates=21500, lr=0.001, gnorm=0.23, clip=0, train_wall=146, wall=6899 (progress_bar.py:260, log())
[2021-04-04 08:19:28]    INFO >> epoch 012:   1265 / 1885 loss=1.155, accuracy=0, mrr=0, ppl=2.23, wps=45398.9, ups=3.38, wpb=13446.9, bsz=128, num_updates=22000, lr=0.001, gnorm=0.226, clip=0, train_wall=147, wall=7047 (progress_bar.py:260, log())
[2021-04-04 08:21:59]    INFO >> epoch 012:   1765 / 1885 loss=1.165, accuracy=0, mrr=0, ppl=2.24, wps=44491.4, ups=3.32, wpb=13409.8, bsz=128, num_updates=22500, lr=0.001, gnorm=0.223, clip=0, train_wall=150, wall=7197 (progress_bar.py:260, log())
[2021-04-04 08:22:36]    INFO >> epoch 012 | loss 1.145 | accuracy 0 | mrr 0 | ppl 2.21 | wps 42234.2 | ups 3.15 | wpb 13428.8 | bsz 128 | num_updates 22620 | lr 0.001 | gnorm 0.227 | clip 0 | train_wall 555 | wall 7234 (progress_bar.py:269, print())
[2021-04-04 08:23:01]    INFO >> epoch 012 | valid on 'valid' subset | loss 1.679 | accuracy 0.739256 | mrr 0.818794 | ppl 3.2 | wps 70786.2 | wpb 27223.6 | bsz 254.5 | num_updates 22620 | best_mrr 0.820601 (progress_bar.py:269, print())
[2021-04-04 08:23:09]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 12 @ 22620 updates, score 0.818794) (writing took 8.068891 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 08:25:08]    INFO >> epoch 013:    380 / 1885 loss=1.106, accuracy=0, mrr=0, ppl=2.15, wps=35299.6, ups=2.64, wpb=13366.6, bsz=127.9, num_updates=23000, lr=0.001, gnorm=0.23, clip=0, train_wall=148, wall=7387 (progress_bar.py:260, log())
[2021-04-04 08:27:39]    INFO >> epoch 013:    880 / 1885 loss=1.115, accuracy=0, mrr=0, ppl=2.17, wps=44844.7, ups=3.33, wpb=13468.1, bsz=128, num_updates=23500, lr=0.001, gnorm=0.231, clip=0, train_wall=149, wall=7537 (progress_bar.py:260, log())
[2021-04-04 08:30:07]    INFO >> epoch 013:   1380 / 1885 loss=1.131, accuracy=0, mrr=0, ppl=2.19, wps=45225.7, ups=3.37, wpb=13412.8, bsz=128, num_updates=24000, lr=0.001, gnorm=0.227, clip=0, train_wall=147, wall=7685 (progress_bar.py:260, log())
[2021-04-04 08:32:35]    INFO >> epoch 013:   1880 / 1885 loss=1.141, accuracy=0, mrr=0, ppl=2.21, wps=45449.7, ups=3.37, wpb=13477.2, bsz=128, num_updates=24500, lr=0.001, gnorm=0.225, clip=0, train_wall=147, wall=7833 (progress_bar.py:260, log())
[2021-04-04 08:32:37]    INFO >> epoch 013 | loss 1.12 | accuracy 0 | mrr 0 | ppl 2.17 | wps 42104.5 | ups 3.14 | wpb 13428.8 | bsz 128 | num_updates 24505 | lr 0.001 | gnorm 0.229 | clip 0 | train_wall 557 | wall 7835 (progress_bar.py:269, print())
[2021-04-04 08:33:03]    INFO >> epoch 013 | valid on 'valid' subset | loss 1.696 | accuracy 0.739538 | mrr 0.818796 | ppl 3.24 | wps 70903.1 | wpb 27223.6 | bsz 254.5 | num_updates 24505 | best_mrr 0.820601 (progress_bar.py:269, print())
[2021-04-04 08:33:10]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 13 @ 24505 updates, score 0.818796) (writing took 7.933583 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 08:35:44]    INFO >> epoch 014:    495 / 1885 loss=1.065, accuracy=0, mrr=0, ppl=2.09, wps=35417.2, ups=2.65, wpb=13385.4, bsz=127.9, num_updates=25000, lr=0.001, gnorm=0.232, clip=0, train_wall=148, wall=8022 (progress_bar.py:260, log())
[2021-04-04 08:38:14]    INFO >> epoch 014:    995 / 1885 loss=1.093, accuracy=0, mrr=0, ppl=2.13, wps=44990.3, ups=3.33, wpb=13517.2, bsz=128, num_updates=25500, lr=0.001, gnorm=0.231, clip=0, train_wall=149, wall=8173 (progress_bar.py:260, log())
[2021-04-04 08:40:43]    INFO >> epoch 014:   1495 / 1885 loss=1.11, accuracy=0, mrr=0, ppl=2.16, wps=45011, ups=3.36, wpb=13387.5, bsz=128, num_updates=26000, lr=0.001, gnorm=0.228, clip=0, train_wall=148, wall=8321 (progress_bar.py:260, log())
[2021-04-04 08:42:39]    INFO >> epoch 014 | loss 1.096 | accuracy 0 | mrr 0 | ppl 2.14 | wps 42054.2 | ups 3.13 | wpb 13428.8 | bsz 128 | num_updates 26390 | lr 0.001 | gnorm 0.23 | clip 0 | train_wall 558 | wall 8437 (progress_bar.py:269, print())
[2021-04-04 08:43:05]    INFO >> epoch 014 | valid on 'valid' subset | loss 1.722 | accuracy 0.738845 | mrr 0.818085 | ppl 3.3 | wps 70342.7 | wpb 27223.6 | bsz 254.5 | num_updates 26390 | best_mrr 0.820601 (progress_bar.py:269, print())
[2021-04-04 08:43:13]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 14 @ 26390 updates, score 0.818085) (writing took 7.978951 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 08:43:52]    INFO >> epoch 015:    110 / 1885 loss=1.103, accuracy=0, mrr=0, ppl=2.15, wps=35609.5, ups=2.65, wpb=13429.6, bsz=127.9, num_updates=26500, lr=0.001, gnorm=0.227, clip=0, train_wall=147, wall=8510 (progress_bar.py:260, log())
[2021-04-04 08:46:21]    INFO >> epoch 015:    610 / 1885 loss=1.051, accuracy=0, mrr=0, ppl=2.07, wps=45117.3, ups=3.36, wpb=13435.1, bsz=128, num_updates=27000, lr=0.001, gnorm=0.236, clip=0, train_wall=148, wall=8659 (progress_bar.py:260, log())
[2021-04-04 08:48:50]    INFO >> epoch 015:   1110 / 1885 loss=1.076, accuracy=0, mrr=0, ppl=2.11, wps=44820.6, ups=3.35, wpb=13390.3, bsz=128, num_updates=27500, lr=0.001, gnorm=0.233, clip=0, train_wall=148, wall=8808 (progress_bar.py:260, log())
[2021-04-04 08:51:19]    INFO >> epoch 015:   1610 / 1885 loss=1.092, accuracy=0, mrr=0, ppl=2.13, wps=44992.5, ups=3.36, wpb=13397.7, bsz=128, num_updates=28000, lr=0.001, gnorm=0.23, clip=0, train_wall=148, wall=8957 (progress_bar.py:260, log())
[2021-04-04 08:52:41]    INFO >> epoch 015 | loss 1.074 | accuracy 0 | mrr 0 | ppl 2.11 | wps 42050.8 | ups 3.13 | wpb 13428.8 | bsz 128 | num_updates 28275 | lr 0.001 | gnorm 0.232 | clip 0 | train_wall 558 | wall 9039 (progress_bar.py:269, print())
[2021-04-04 08:53:07]    INFO >> epoch 015 | valid on 'valid' subset | loss 1.738 | accuracy 0.737786 | mrr 0.817286 | ppl 3.34 | wps 70264.8 | wpb 27223.6 | bsz 254.5 | num_updates 28275 | best_mrr 0.820601 (progress_bar.py:269, print())
[2021-04-04 08:53:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/php/gpt2/checkpoints/checkpoint_last.pt (epoch 15 @ 28275 updates, score 0.817286) (writing took 7.897292 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 08:53:14]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:176, should_stop_early())
[2021-04-04 08:53:14]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:259, single_main())
[2021-04-04 08:53:14]    INFO >> done training in 9071.7 seconds (train.py:271, single_main())
