nohup: ignoring input
[2021-04-04 02:04:43]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/completion/gpt2/config/csn_feng/python.yml (train.py:291, cli_main())
[2021-04-04 02:04:43]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:293, cli_main())
[2021-04-04 02:04:45]    INFO >> distributed init (rank 0): tcp://localhost:16984 (distributed_utils.py:84, distributed_init())
[2021-04-04 02:04:45]    INFO >> distributed init (rank 3): tcp://localhost:16984 (distributed_utils.py:84, distributed_init())
[2021-04-04 02:04:45]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 02:04:45]    INFO >> distributed init (rank 2): tcp://localhost:16984 (distributed_utils.py:84, distributed_init())
[2021-04-04 02:04:45]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 02:04:45]    INFO >> distributed init (rank 1): tcp://localhost:16984 (distributed_utils.py:84, distributed_init())
[2021-04-04 02:04:45]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 02:04:45]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 02:04:45]    INFO >> initialized host node14 as rank 0 (distributed_utils.py:93, distributed_init())
[2021-04-04 02:04:45]    INFO >> initialized host node14 as rank 2 (distributed_utils.py:93, distributed_init())
[2021-04-04 02:04:45]    INFO >> initialized host node14 as rank 1 (distributed_utils.py:93, distributed_init())
[2021-04-04 02:04:45]    INFO >> initialized host node14 as rank 3 (distributed_utils.py:93, distributed_init())
[2021-04-04 02:04:51]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16984', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:201, single_main())
[2021-04-04 02:04:51]    INFO >> [code_tokens] dictionary: 50000 types (completion.py:101, setup_task())
[2021-04-04 02:04:51]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 02:04:51]    INFO >> loaded 13914 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/valid.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 02:04:52]    INFO >> GPT2(
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50000, 300, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (1): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (2): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (3): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (4): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (5): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
    )
    (out_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
  )
) (train.py:212, single_main())
[2021-04-04 02:04:52]    INFO >> model completion_gpt2, criterion CompletionCrossEntropyCriterion (train.py:213, single_main())
[2021-04-04 02:04:52]    INFO >> num. model params: 23076864 (num. trained: 23076864) (train.py:214, single_main())
[2021-04-04 02:04:52]    INFO >> training on 4 GPUs (train.py:221, single_main())
[2021-04-04 02:04:52]    INFO >> max tokens per GPU = 100000.0 and max sentences per GPU = 32 (train.py:222, single_main())
[2021-04-04 02:04:52]    INFO >> no existing checkpoint found checkpoint_best.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-04 02:04:52]    INFO >> loading train data for epoch 1 (ncc_trainers.py:284, get_train_iterator())
[2021-04-04 02:04:52]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 02:04:52]    INFO >> loaded 251820 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/train.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 02:04:53]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 02:07:32]    INFO >> epoch 001:    500 / 1968 loss=4.982, accuracy=0, mrr=0, ppl=31.61, wps=40042.7, ups=3.28, wpb=12227.8, bsz=128, num_updates=500, lr=0.001, gnorm=0.915, clip=0, train_wall=152, wall=160 (progress_bar.py:260, log())
[2021-04-04 02:09:57]    INFO >> epoch 001:   1000 / 1968 loss=3.623, accuracy=0, mrr=0, ppl=12.32, wps=42015.2, ups=3.44, wpb=12231.4, bsz=128, num_updates=1000, lr=0.001, gnorm=0.788, clip=0, train_wall=144, wall=306 (progress_bar.py:260, log())
[2021-04-04 02:12:23]    INFO >> epoch 001:   1500 / 1968 loss=3.043, accuracy=0, mrr=0, ppl=8.24, wps=42019.5, ups=3.44, wpb=12216.6, bsz=128, num_updates=1500, lr=0.001, gnorm=0.734, clip=0, train_wall=144, wall=451 (progress_bar.py:260, log())
[2021-04-04 02:14:40]    INFO >> epoch 001 | loss 3.614 | accuracy 0 | mrr 0 | ppl 12.25 | wps 41513 | ups 3.39 | wpb 12250 | bsz 128 | num_updates 1968 | lr 0.001 | gnorm 0.781 | clip 0 | train_wall 577 | wall 588 (progress_bar.py:269, print())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 02:15:10]    INFO >> epoch 001 | valid on 'valid' subset | loss 2.749 | accuracy 0.587325 | mrr 0.697131 | ppl 6.72 | wps 55153.3 | wpb 24594.9 | bsz 253 | num_updates 1968 (progress_bar.py:269, print())
[2021-04-04 02:15:11]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 1 @ 1968 updates, score 0.697131) (writing took 0.973934 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 02:15:26]    INFO >> epoch 002:     32 / 1968 loss=2.756, accuracy=0, mrr=0, ppl=6.75, wps=33616.4, ups=2.73, wpb=12329.1, bsz=127.8, num_updates=2000, lr=0.001, gnorm=0.678, clip=0, train_wall=145, wall=635 (progress_bar.py:260, log())
[2021-04-04 02:17:52]    INFO >> epoch 002:    532 / 1968 loss=2.58, accuracy=0, mrr=0, ppl=5.98, wps=41924, ups=3.43, wpb=12209.1, bsz=128, num_updates=2500, lr=0.001, gnorm=0.621, clip=0, train_wall=145, wall=780 (progress_bar.py:260, log())
[2021-04-04 02:20:17]    INFO >> epoch 002:   1032 / 1968 loss=2.455, accuracy=0, mrr=0, ppl=5.48, wps=42078.4, ups=3.44, wpb=12236.4, bsz=128, num_updates=3000, lr=0.001, gnorm=0.555, clip=0, train_wall=144, wall=926 (progress_bar.py:260, log())
[2021-04-04 02:22:42]    INFO >> epoch 002:   1532 / 1968 loss=2.37, accuracy=0, mrr=0, ppl=5.17, wps=42164.3, ups=3.45, wpb=12231.5, bsz=128, num_updates=3500, lr=0.001, gnorm=0.521, clip=0, train_wall=144, wall=1071 (progress_bar.py:260, log())
[2021-04-04 02:24:50]    INFO >> epoch 002 | loss 2.438 | accuracy 0 | mrr 0 | ppl 5.42 | wps 39516.9 | ups 3.23 | wpb 12250 | bsz 128 | num_updates 3936 | lr 0.001 | gnorm 0.552 | clip 0 | train_wall 568 | wall 1198 (progress_bar.py:269, print())
[2021-04-04 02:25:17]    INFO >> epoch 002 | valid on 'valid' subset | loss 2.497 | accuracy 0.616816 | mrr 0.721685 | ppl 5.64 | wps 65062.6 | wpb 24594.9 | bsz 253 | num_updates 3936 | best_mrr 0.721685 (progress_bar.py:269, print())
[2021-04-04 02:25:31]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 2 @ 3936 updates, score 0.721685) (writing took 14.623619 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 02:25:55]    INFO >> epoch 003:     64 / 1968 loss=2.318, accuracy=0, mrr=0, ppl=4.99, wps=31930, ups=2.59, wpb=12312.9, bsz=127.8, num_updates=4000, lr=0.001, gnorm=0.498, clip=0, train_wall=144, wall=1264 (progress_bar.py:260, log())
[2021-04-04 02:28:20]    INFO >> epoch 003:    564 / 1968 loss=2.263, accuracy=0, mrr=0, ppl=4.8, wps=42263.1, ups=3.46, wpb=12209.3, bsz=128, num_updates=4500, lr=0.001, gnorm=0.473, clip=0, train_wall=143, wall=1408 (progress_bar.py:260, log())
[2021-04-04 02:30:44]    INFO >> epoch 003:   1064 / 1968 loss=2.22, accuracy=0, mrr=0, ppl=4.66, wps=42381.5, ups=3.46, wpb=12243.7, bsz=128, num_updates=5000, lr=0.001, gnorm=0.463, clip=0, train_wall=143, wall=1552 (progress_bar.py:260, log())
[2021-04-04 02:33:09]    INFO >> epoch 003:   1564 / 1968 loss=2.178, accuracy=0, mrr=0, ppl=4.52, wps=42163.3, ups=3.44, wpb=12243.8, bsz=128, num_updates=5500, lr=0.001, gnorm=0.435, clip=0, train_wall=144, wall=1698 (progress_bar.py:260, log())
[2021-04-04 02:35:08]    INFO >> epoch 003 | loss 2.21 | accuracy 0 | mrr 0 | ppl 4.63 | wps 39029.6 | ups 3.19 | wpb 12250 | bsz 128 | num_updates 5904 | lr 0.001 | gnorm 0.451 | clip 0 | train_wall 566 | wall 1816 (progress_bar.py:269, print())
[2021-04-04 02:35:34]    INFO >> epoch 003 | valid on 'valid' subset | loss 2.429 | accuracy 0.628142 | mrr 0.730559 | ppl 5.38 | wps 65012 | wpb 24594.9 | bsz 253 | num_updates 5904 | best_mrr 0.730559 (progress_bar.py:269, print())
[2021-04-04 02:35:49]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 3 @ 5904 updates, score 0.730559) (writing took 14.717318 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 02:36:23]    INFO >> epoch 004:     96 / 1968 loss=2.155, accuracy=0, mrr=0, ppl=4.45, wps=31811.3, ups=2.58, wpb=12310.4, bsz=127.8, num_updates=6000, lr=0.001, gnorm=0.427, clip=0, train_wall=145, wall=1891 (progress_bar.py:260, log())
[2021-04-04 02:38:48]    INFO >> epoch 004:    596 / 1968 loss=2.122, accuracy=0, mrr=0, ppl=4.35, wps=41794.8, ups=3.43, wpb=12187.1, bsz=128, num_updates=6500, lr=0.001, gnorm=0.411, clip=0, train_wall=145, wall=2037 (progress_bar.py:260, log())
[2021-04-04 02:41:13]    INFO >> epoch 004:   1096 / 1968 loss=2.095, accuracy=0, mrr=0, ppl=4.27, wps=42408, ups=3.46, wpb=12261, bsz=128, num_updates=7000, lr=0.001, gnorm=0.404, clip=0, train_wall=144, wall=2181 (progress_bar.py:260, log())
[2021-04-04 02:43:39]    INFO >> epoch 004:   1596 / 1968 loss=2.068, accuracy=0, mrr=0, ppl=4.19, wps=42055.6, ups=3.44, wpb=12241.9, bsz=128, num_updates=7500, lr=0.001, gnorm=0.394, clip=0, train_wall=144, wall=2327 (progress_bar.py:260, log())
[2021-04-04 02:45:27]    INFO >> epoch 004 | loss 2.09 | accuracy 0 | mrr 0 | ppl 4.26 | wps 38904.9 | ups 3.18 | wpb 12250 | bsz 128 | num_updates 7872 | lr 0.001 | gnorm 0.401 | clip 0 | train_wall 568 | wall 2436 (progress_bar.py:269, print())
[2021-04-04 02:45:54]    INFO >> epoch 004 | valid on 'valid' subset | loss 2.407 | accuracy 0.631791 | mrr 0.733662 | ppl 5.31 | wps 65298.5 | wpb 24594.9 | bsz 253 | num_updates 7872 | best_mrr 0.733662 (progress_bar.py:269, print())
[2021-04-04 02:46:09]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 4 @ 7872 updates, score 0.733662) (writing took 14.797415 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 02:46:52]    INFO >> epoch 005:    128 / 1968 loss=2.055, accuracy=0, mrr=0, ppl=4.15, wps=31832.2, ups=2.58, wpb=12317.2, bsz=127.8, num_updates=8000, lr=0.001, gnorm=0.389, clip=0, train_wall=145, wall=2520 (progress_bar.py:260, log())
[2021-04-04 02:49:17]    INFO >> epoch 005:    628 / 1968 loss=2.026, accuracy=0, mrr=0, ppl=4.07, wps=42002, ups=3.45, wpb=12190.1, bsz=128, num_updates=8500, lr=0.001, gnorm=0.371, clip=0, train_wall=144, wall=2666 (progress_bar.py:260, log())
[2021-04-04 02:51:42]    INFO >> epoch 005:   1128 / 1968 loss=2.01, accuracy=0, mrr=0, ppl=4.03, wps=42171.3, ups=3.45, wpb=12228.9, bsz=128, num_updates=9000, lr=0.001, gnorm=0.375, clip=0, train_wall=144, wall=2811 (progress_bar.py:260, log())
[2021-04-04 02:54:08]    INFO >> epoch 005:   1628 / 1968 loss=1.991, accuracy=0, mrr=0, ppl=3.97, wps=42013.1, ups=3.42, wpb=12280.5, bsz=128, num_updates=9500, lr=0.001, gnorm=0.368, clip=0, train_wall=145, wall=2957 (progress_bar.py:260, log())
[2021-04-04 02:55:48]    INFO >> epoch 005 | loss 2.006 | accuracy 0 | mrr 0 | ppl 4.02 | wps 38844 | ups 3.17 | wpb 12250 | bsz 128 | num_updates 9840 | lr 0.001 | gnorm 0.372 | clip 0 | train_wall 569 | wall 3056 (progress_bar.py:269, print())
[2021-04-04 02:56:15]    INFO >> epoch 005 | valid on 'valid' subset | loss 2.398 | accuracy 0.633696 | mrr 0.735228 | ppl 5.27 | wps 64570.2 | wpb 24594.9 | bsz 253 | num_updates 9840 | best_mrr 0.735228 (progress_bar.py:269, print())
[2021-04-04 02:56:29]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 5 @ 9840 updates, score 0.735228) (writing took 14.673086 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 02:57:22]    INFO >> epoch 006:    160 / 1968 loss=1.961, accuracy=0, mrr=0, ppl=3.89, wps=31741, ups=2.58, wpb=12297.5, bsz=127.8, num_updates=10000, lr=0.001, gnorm=0.353, clip=0, train_wall=145, wall=3150 (progress_bar.py:260, log())
[2021-04-04 02:59:47]    INFO >> epoch 006:    660 / 1968 loss=1.933, accuracy=0, mrr=0, ppl=3.82, wps=42337.8, ups=3.46, wpb=12251.4, bsz=128, num_updates=10500, lr=0.001, gnorm=0.326, clip=0, train_wall=144, wall=3295 (progress_bar.py:260, log())
[2021-04-04 03:02:10]    INFO >> epoch 006:   1160 / 1968 loss=1.954, accuracy=0, mrr=0, ppl=3.87, wps=42883.2, ups=3.49, wpb=12302, bsz=128, num_updates=11000, lr=0.001, gnorm=0.321, clip=0, train_wall=142, wall=3439 (progress_bar.py:260, log())
[2021-04-04 03:04:35]    INFO >> epoch 006:   1660 / 1968 loss=1.96, accuracy=0, mrr=0, ppl=3.89, wps=42203.5, ups=3.44, wpb=12253.8, bsz=128, num_updates=11500, lr=0.001, gnorm=0.321, clip=0, train_wall=144, wall=3584 (progress_bar.py:260, log())
[2021-04-04 03:06:05]    INFO >> epoch 006 | loss 1.949 | accuracy 0 | mrr 0 | ppl 3.86 | wps 39065.3 | ups 3.19 | wpb 12250 | bsz 128 | num_updates 11808 | lr 0.001 | gnorm 0.321 | clip 0 | train_wall 565 | wall 3674 (progress_bar.py:269, print())
[2021-04-04 03:06:32]    INFO >> epoch 006 | valid on 'valid' subset | loss 2.338 | accuracy 0.642375 | mrr 0.741817 | ppl 5.06 | wps 65594.7 | wpb 24594.9 | bsz 253 | num_updates 11808 | best_mrr 0.741817 (progress_bar.py:269, print())
[2021-04-04 03:06:46]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 6 @ 11808 updates, score 0.741817) (writing took 14.624874 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 03:07:48]    INFO >> epoch 007:    192 / 1968 loss=1.917, accuracy=0, mrr=0, ppl=3.78, wps=31630.5, ups=2.6, wpb=12177.6, bsz=127.9, num_updates=12000, lr=0.001, gnorm=0.313, clip=0, train_wall=144, wall=3776 (progress_bar.py:260, log())
[2021-04-04 03:10:14]    INFO >> epoch 007:    692 / 1968 loss=1.872, accuracy=0, mrr=0, ppl=3.66, wps=42016.5, ups=3.43, wpb=12261.9, bsz=128, num_updates=12500, lr=0.001, gnorm=0.314, clip=0, train_wall=145, wall=3922 (progress_bar.py:260, log())
[2021-04-04 03:12:39]    INFO >> epoch 007:   1192 / 1968 loss=1.89, accuracy=0, mrr=0, ppl=3.71, wps=42354, ups=3.45, wpb=12276.5, bsz=128, num_updates=13000, lr=0.001, gnorm=0.313, clip=0, train_wall=144, wall=4067 (progress_bar.py:260, log())
[2021-04-04 03:15:05]    INFO >> epoch 007:   1692 / 1968 loss=1.904, accuracy=0, mrr=0, ppl=3.74, wps=41813.8, ups=3.41, wpb=12253, bsz=128, num_updates=13500, lr=0.001, gnorm=0.309, clip=0, train_wall=145, wall=4214 (progress_bar.py:260, log())
[2021-04-04 03:16:26]    INFO >> epoch 007 | loss 1.887 | accuracy 0 | mrr 0 | ppl 3.7 | wps 38835.2 | ups 3.17 | wpb 12250 | bsz 128 | num_updates 13776 | lr 0.001 | gnorm 0.311 | clip 0 | train_wall 569 | wall 4294 (progress_bar.py:269, print())
[2021-04-04 03:16:53]    INFO >> epoch 007 | valid on 'valid' subset | loss 2.342 | accuracy 0.643333 | mrr 0.742458 | ppl 5.07 | wps 65044.1 | wpb 24594.9 | bsz 253 | num_updates 13776 | best_mrr 0.742458 (progress_bar.py:269, print())
[2021-04-04 03:17:07]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 7 @ 13776 updates, score 0.742458) (writing took 14.484310 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 03:18:18]    INFO >> epoch 008:    224 / 1968 loss=1.856, accuracy=0, mrr=0, ppl=3.62, wps=31733.9, ups=2.59, wpb=12230.5, bsz=127.8, num_updates=14000, lr=0.001, gnorm=0.307, clip=0, train_wall=144, wall=4406 (progress_bar.py:260, log())
[2021-04-04 03:20:42]    INFO >> epoch 008:    724 / 1968 loss=1.824, accuracy=0, mrr=0, ppl=3.54, wps=42468.6, ups=3.47, wpb=12253.6, bsz=128, num_updates=14500, lr=0.001, gnorm=0.303, clip=0, train_wall=143, wall=4551 (progress_bar.py:260, log())
[2021-04-04 03:23:08]    INFO >> epoch 008:   1224 / 1968 loss=1.843, accuracy=0, mrr=0, ppl=3.59, wps=42031.3, ups=3.44, wpb=12232.9, bsz=128, num_updates=15000, lr=0.001, gnorm=0.303, clip=0, train_wall=144, wall=4696 (progress_bar.py:260, log())
[2021-04-04 03:25:33]    INFO >> epoch 008:   1724 / 1968 loss=1.858, accuracy=0, mrr=0, ppl=3.62, wps=42261.6, ups=3.45, wpb=12252.2, bsz=128, num_updates=15500, lr=0.001, gnorm=0.301, clip=0, train_wall=144, wall=4841 (progress_bar.py:260, log())
[2021-04-04 03:26:44]    INFO >> epoch 008 | loss 1.838 | accuracy 0 | mrr 0 | ppl 3.57 | wps 38977.2 | ups 3.18 | wpb 12250 | bsz 128 | num_updates 15744 | lr 0.001 | gnorm 0.303 | clip 0 | train_wall 567 | wall 4913 (progress_bar.py:269, print())
[2021-04-04 03:27:11]    INFO >> epoch 008 | valid on 'valid' subset | loss 2.357 | accuracy 0.642998 | mrr 0.742255 | ppl 5.12 | wps 65174.2 | wpb 24594.9 | bsz 253 | num_updates 15744 | best_mrr 0.742458 (progress_bar.py:269, print())
[2021-04-04 03:27:19]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_last.pt (epoch 8 @ 15744 updates, score 0.742255) (writing took 7.839705 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 03:28:40]    INFO >> epoch 009:    256 / 1968 loss=1.802, accuracy=0, mrr=0, ppl=3.49, wps=32775.1, ups=2.67, wpb=12282.1, bsz=127.9, num_updates=16000, lr=0.001, gnorm=0.299, clip=0, train_wall=146, wall=5028 (progress_bar.py:260, log())
[2021-04-04 03:31:05]    INFO >> epoch 009:    756 / 1968 loss=1.781, accuracy=0, mrr=0, ppl=3.44, wps=42265.1, ups=3.46, wpb=12217.2, bsz=128, num_updates=16500, lr=0.001, gnorm=0.306, clip=0, train_wall=143, wall=5173 (progress_bar.py:260, log())
[2021-04-04 03:33:31]    INFO >> epoch 009:   1256 / 1968 loss=1.799, accuracy=0, mrr=0, ppl=3.48, wps=41990.5, ups=3.42, wpb=12266, bsz=128, num_updates=17000, lr=0.001, gnorm=0.304, clip=0, train_wall=145, wall=5319 (progress_bar.py:260, log())
[2021-04-04 03:35:56]    INFO >> epoch 009:   1756 / 1968 loss=1.815, accuracy=0, mrr=0, ppl=3.52, wps=42212.5, ups=3.44, wpb=12259.6, bsz=128, num_updates=17500, lr=0.001, gnorm=0.293, clip=0, train_wall=144, wall=5464 (progress_bar.py:260, log())
[2021-04-04 03:36:57]    INFO >> epoch 009 | loss 1.794 | accuracy 0 | mrr 0 | ppl 3.47 | wps 39338.2 | ups 3.21 | wpb 12250 | bsz 128 | num_updates 17712 | lr 0.001 | gnorm 0.3 | clip 0 | train_wall 568 | wall 5526 (progress_bar.py:269, print())
[2021-04-04 03:37:24]    INFO >> epoch 009 | valid on 'valid' subset | loss 2.357 | accuracy 0.643713 | mrr 0.742468 | ppl 5.12 | wps 65014.3 | wpb 24594.9 | bsz 253 | num_updates 17712 | best_mrr 0.742468 (progress_bar.py:269, print())
[2021-04-04 03:37:38]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_best.pt (epoch 9 @ 17712 updates, score 0.742468) (writing took 14.569199 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 03:39:07]    INFO >> epoch 010:    288 / 1968 loss=1.756, accuracy=0, mrr=0, ppl=3.38, wps=31905.2, ups=2.62, wpb=12177.3, bsz=127.9, num_updates=18000, lr=0.001, gnorm=0.297, clip=0, train_wall=142, wall=5655 (progress_bar.py:260, log())
[2021-04-04 03:41:32]    INFO >> epoch 010:    788 / 1968 loss=1.742, accuracy=0, mrr=0, ppl=3.35, wps=42193, ups=3.45, wpb=12237.2, bsz=128, num_updates=18500, lr=0.001, gnorm=0.306, clip=0, train_wall=144, wall=5800 (progress_bar.py:260, log())
[2021-04-04 03:43:57]    INFO >> epoch 010:   1288 / 1968 loss=1.761, accuracy=0, mrr=0, ppl=3.39, wps=42200.2, ups=3.44, wpb=12284.2, bsz=128, num_updates=19000, lr=0.001, gnorm=0.293, clip=0, train_wall=144, wall=5946 (progress_bar.py:260, log())
[2021-04-04 03:46:22]    INFO >> epoch 010:   1788 / 1968 loss=1.781, accuracy=0, mrr=0, ppl=3.44, wps=42395.8, ups=3.46, wpb=12259.7, bsz=128, num_updates=19500, lr=0.001, gnorm=0.29, clip=0, train_wall=144, wall=6090 (progress_bar.py:260, log())
[2021-04-04 03:47:15]    INFO >> epoch 010 | loss 1.756 | accuracy 0 | mrr 0 | ppl 3.38 | wps 39012.5 | ups 3.18 | wpb 12250 | bsz 128 | num_updates 19680 | lr 0.001 | gnorm 0.297 | clip 0 | train_wall 566 | wall 6144 (progress_bar.py:269, print())
[2021-04-04 03:47:42]    INFO >> epoch 010 | valid on 'valid' subset | loss 2.378 | accuracy 0.643887 | mrr 0.74223 | ppl 5.2 | wps 64963 | wpb 24594.9 | bsz 253 | num_updates 19680 | best_mrr 0.742468 (progress_bar.py:269, print())
[2021-04-04 03:47:50]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_last.pt (epoch 10 @ 19680 updates, score 0.74223) (writing took 7.832048 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 03:49:28]    INFO >> epoch 011:    320 / 1968 loss=1.714, accuracy=0, mrr=0, ppl=3.28, wps=32941.4, ups=2.68, wpb=12285, bsz=127.9, num_updates=20000, lr=0.001, gnorm=0.298, clip=0, train_wall=145, wall=6277 (progress_bar.py:260, log())
[2021-04-04 03:51:53]    INFO >> epoch 011:    820 / 1968 loss=1.706, accuracy=0, mrr=0, ppl=3.26, wps=42480.3, ups=3.45, wpb=12319.2, bsz=128, num_updates=20500, lr=0.001, gnorm=0.298, clip=0, train_wall=144, wall=6422 (progress_bar.py:260, log())
[2021-04-04 03:54:19]    INFO >> epoch 011:   1320 / 1968 loss=1.729, accuracy=0, mrr=0, ppl=3.32, wps=41904.9, ups=3.43, wpb=12215.3, bsz=128, num_updates=21000, lr=0.001, gnorm=0.294, clip=0, train_wall=145, wall=6567 (progress_bar.py:260, log())
[2021-04-04 03:56:42]    INFO >> epoch 011:   1820 / 1968 loss=1.747, accuracy=0, mrr=0, ppl=3.36, wps=42659.6, ups=3.5, wpb=12205.7, bsz=128, num_updates=21500, lr=0.001, gnorm=0.292, clip=0, train_wall=142, wall=6710 (progress_bar.py:260, log())
[2021-04-04 03:57:26]    INFO >> epoch 011 | loss 1.72 | accuracy 0 | mrr 0 | ppl 3.3 | wps 39481.3 | ups 3.22 | wpb 12250 | bsz 128 | num_updates 21648 | lr 0.001 | gnorm 0.296 | clip 0 | train_wall 566 | wall 6754 (progress_bar.py:269, print())
[2021-04-04 03:57:52]    INFO >> epoch 011 | valid on 'valid' subset | loss 2.4 | accuracy 0.641859 | mrr 0.741034 | ppl 5.28 | wps 65484.6 | wpb 24594.9 | bsz 253 | num_updates 21648 | best_mrr 0.742468 (progress_bar.py:269, print())
[2021-04-04 03:58:00]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_last.pt (epoch 11 @ 21648 updates, score 0.741034) (writing took 7.839737 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 03:59:49]    INFO >> epoch 012:    352 / 1968 loss=1.672, accuracy=0, mrr=0, ppl=3.19, wps=32804.6, ups=2.68, wpb=12239.9, bsz=127.8, num_updates=22000, lr=0.001, gnorm=0.302, clip=0, train_wall=145, wall=6897 (progress_bar.py:260, log())
[2021-04-04 04:02:15]    INFO >> epoch 012:    852 / 1968 loss=1.681, accuracy=0, mrr=0, ppl=3.21, wps=41792.9, ups=3.42, wpb=12223.1, bsz=128, num_updates=22500, lr=0.001, gnorm=0.301, clip=0, train_wall=145, wall=7043 (progress_bar.py:260, log())
[2021-04-04 04:04:39]    INFO >> epoch 012:   1352 / 1968 loss=1.699, accuracy=0, mrr=0, ppl=3.25, wps=42470.9, ups=3.47, wpb=12256.9, bsz=128, num_updates=23000, lr=0.001, gnorm=0.296, clip=0, train_wall=143, wall=7188 (progress_bar.py:260, log())
[2021-04-04 04:07:05]    INFO >> epoch 012:   1852 / 1968 loss=1.714, accuracy=0, mrr=0, ppl=3.28, wps=42089.6, ups=3.43, wpb=12269.3, bsz=128, num_updates=23500, lr=0.001, gnorm=0.294, clip=0, train_wall=145, wall=7333 (progress_bar.py:260, log())
[2021-04-04 04:07:40]    INFO >> epoch 012 | loss 1.689 | accuracy 0 | mrr 0 | ppl 3.22 | wps 39280.5 | ups 3.21 | wpb 12250 | bsz 128 | num_updates 23616 | lr 0.001 | gnorm 0.298 | clip 0 | train_wall 569 | wall 7368 (progress_bar.py:269, print())
[2021-04-04 04:08:06]    INFO >> epoch 012 | valid on 'valid' subset | loss 2.406 | accuracy 0.642453 | mrr 0.741035 | ppl 5.3 | wps 64946.7 | wpb 24594.9 | bsz 253 | num_updates 23616 | best_mrr 0.742468 (progress_bar.py:269, print())
[2021-04-04 04:08:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_last.pt (epoch 12 @ 23616 updates, score 0.741035) (writing took 7.826588 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 04:10:11]    INFO >> epoch 013:    384 / 1968 loss=1.635, accuracy=0, mrr=0, ppl=3.11, wps=33006.8, ups=2.69, wpb=12265, bsz=127.9, num_updates=24000, lr=0.001, gnorm=0.302, clip=0, train_wall=144, wall=7519 (progress_bar.py:260, log())
[2021-04-04 04:12:37]    INFO >> epoch 013:    884 / 1968 loss=1.65, accuracy=0, mrr=0, ppl=3.14, wps=41642, ups=3.41, wpb=12199.5, bsz=128, num_updates=24500, lr=0.001, gnorm=0.305, clip=0, train_wall=145, wall=7666 (progress_bar.py:260, log())
[2021-04-04 04:15:02]    INFO >> epoch 013:   1384 / 1968 loss=1.671, accuracy=0, mrr=0, ppl=3.18, wps=42261, ups=3.45, wpb=12242.9, bsz=128, num_updates=25000, lr=0.001, gnorm=0.293, clip=0, train_wall=144, wall=7810 (progress_bar.py:260, log())
[2021-04-04 04:17:27]    INFO >> epoch 013:   1884 / 1968 loss=1.69, accuracy=0, mrr=0, ppl=3.23, wps=42353.6, ups=3.44, wpb=12296.6, bsz=128, num_updates=25500, lr=0.001, gnorm=0.296, clip=0, train_wall=144, wall=7956 (progress_bar.py:260, log())
[2021-04-04 04:17:52]    INFO >> epoch 013 | loss 1.66 | accuracy 0 | mrr 0 | ppl 3.16 | wps 39338.3 | ups 3.21 | wpb 12250 | bsz 128 | num_updates 25584 | lr 0.001 | gnorm 0.299 | clip 0 | train_wall 568 | wall 7981 (progress_bar.py:269, print())
[2021-04-04 04:18:19]    INFO >> epoch 013 | valid on 'valid' subset | loss 2.441 | accuracy 0.640689 | mrr 0.739357 | ppl 5.43 | wps 64587.2 | wpb 24594.9 | bsz 253 | num_updates 25584 | best_mrr 0.742468 (progress_bar.py:269, print())
[2021-04-04 04:18:27]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_last.pt (epoch 13 @ 25584 updates, score 0.739357) (writing took 7.774698 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 04:20:34]    INFO >> epoch 014:    416 / 1968 loss=1.604, accuracy=0, mrr=0, ppl=3.04, wps=32722.7, ups=2.67, wpb=12236.8, bsz=127.9, num_updates=26000, lr=0.001, gnorm=0.303, clip=0, train_wall=145, wall=8143 (progress_bar.py:260, log())
[2021-04-04 04:23:00]    INFO >> epoch 014:    916 / 1968 loss=1.621, accuracy=0, mrr=0, ppl=3.08, wps=41932.3, ups=3.42, wpb=12246.1, bsz=128, num_updates=26500, lr=0.001, gnorm=0.305, clip=0, train_wall=145, wall=8289 (progress_bar.py:260, log())
[2021-04-04 04:25:25]    INFO >> epoch 014:   1416 / 1968 loss=1.646, accuracy=0, mrr=0, ppl=3.13, wps=42373.3, ups=3.45, wpb=12293.3, bsz=128, num_updates=27000, lr=0.001, gnorm=0.301, clip=0, train_wall=144, wall=8434 (progress_bar.py:260, log())
[2021-04-04 04:27:51]    INFO >> epoch 014:   1916 / 1968 loss=1.665, accuracy=0, mrr=0, ppl=3.17, wps=42117.2, ups=3.44, wpb=12238.2, bsz=128, num_updates=27500, lr=0.001, gnorm=0.296, clip=0, train_wall=144, wall=8579 (progress_bar.py:260, log())
[2021-04-04 04:28:06]    INFO >> epoch 014 | loss 1.632 | accuracy 0 | mrr 0 | ppl 3.1 | wps 39266.9 | ups 3.21 | wpb 12250 | bsz 128 | num_updates 27552 | lr 0.001 | gnorm 0.302 | clip 0 | train_wall 569 | wall 8595 (progress_bar.py:269, print())
[2021-04-04 04:28:33]    INFO >> epoch 014 | valid on 'valid' subset | loss 2.46 | accuracy 0.641329 | mrr 0.739901 | ppl 5.5 | wps 65105.5 | wpb 24594.9 | bsz 253 | num_updates 27552 | best_mrr 0.742468 (progress_bar.py:269, print())
[2021-04-04 04:28:41]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/python/gpt2/checkpoints/checkpoint_last.pt (epoch 14 @ 27552 updates, score 0.739901) (writing took 7.809059 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 04:28:41]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:176, should_stop_early())
[2021-04-04 04:28:41]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:259, single_main())
[2021-04-04 04:28:41]    INFO >> done training in 8628.1 seconds (train.py:271, single_main())
