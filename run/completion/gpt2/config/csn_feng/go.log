nohup: ignoring input
[2021-04-04 05:01:57]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/completion/gpt2/config/csn_feng/go.yml (train.py:291, cli_main())
[2021-04-04 05:01:57]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:293, cli_main())
[2021-04-04 05:01:59]    INFO >> distributed init (rank 0): tcp://localhost:14472 (distributed_utils.py:84, distributed_init())
[2021-04-04 05:01:59]    INFO >> distributed init (rank 2): tcp://localhost:14472 (distributed_utils.py:84, distributed_init())
[2021-04-04 05:01:59]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 05:01:59]    INFO >> distributed init (rank 1): tcp://localhost:14472 (distributed_utils.py:84, distributed_init())
[2021-04-04 05:01:59]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 05:01:59]    INFO >> distributed init (rank 3): tcp://localhost:14472 (distributed_utils.py:84, distributed_init())
[2021-04-04 05:01:59]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 05:01:59]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 05:01:59]    INFO >> initialized host node14 as rank 3 (distributed_utils.py:93, distributed_init())
[2021-04-04 05:01:59]    INFO >> initialized host node14 as rank 0 (distributed_utils.py:93, distributed_init())
[2021-04-04 05:01:59]    INFO >> initialized host node14 as rank 2 (distributed_utils.py:93, distributed_init())
[2021-04-04 05:01:59]    INFO >> initialized host node14 as rank 1 (distributed_utils.py:93, distributed_init())
[2021-04-04 05:02:05]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14472', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:201, single_main())
[2021-04-04 05:02:05]    INFO >> [code_tokens] dictionary: 50000 types (completion.py:101, setup_task())
[2021-04-04 05:02:05]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 05:02:05]    INFO >> loaded 7325 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/valid.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 05:02:05]    INFO >> GPT2(
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50000, 300, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (1): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (2): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (3): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (4): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (5): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
    )
    (out_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
  )
) (train.py:212, single_main())
[2021-04-04 05:02:05]    INFO >> model completion_gpt2, criterion CompletionCrossEntropyCriterion (train.py:213, single_main())
[2021-04-04 05:02:05]    INFO >> num. model params: 23076864 (num. trained: 23076864) (train.py:214, single_main())
[2021-04-04 05:02:06]    INFO >> training on 4 GPUs (train.py:221, single_main())
[2021-04-04 05:02:06]    INFO >> max tokens per GPU = 100000.0 and max sentences per GPU = 32 (train.py:222, single_main())
[2021-04-04 05:02:06]    INFO >> no existing checkpoint found checkpoint_best.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-04 05:02:06]    INFO >> loading train data for epoch 1 (ncc_trainers.py:284, get_train_iterator())
[2021-04-04 05:02:06]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 05:02:06]    INFO >> loaded 167288 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/train.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 05:02:06]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 05:04:52]    INFO >> epoch 001:    500 / 1307 loss=4.01, accuracy=0, mrr=0, ppl=16.11, wps=38164, ups=3.14, wpb=12136.7, bsz=128, num_updates=500, lr=0.001, gnorm=0.876, clip=0, train_wall=159, wall=166 (progress_bar.py:260, log())
[2021-04-04 05:07:23]    INFO >> epoch 001:   1000 / 1307 loss=2.656, accuracy=0, mrr=0, ppl=6.3, wps=39899.8, ups=3.3, wpb=12090.2, bsz=128, num_updates=1000, lr=0.001, gnorm=0.64, clip=0, train_wall=150, wall=318 (progress_bar.py:260, log())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 05:08:58]    INFO >> epoch 001 | loss 3.086 | accuracy 0 | mrr 0 | ppl 8.49 | wps 39122.6 | ups 3.23 | wpb 12113.3 | bsz 128 | num_updates 1307 | lr 0.001 | gnorm 0.713 | clip 0 | train_wall 402 | wall 412 (progress_bar.py:269, print())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 05:09:19]    INFO >> epoch 001 | valid on 'valid' subset | loss 2.31 | accuracy 0.662439 | mrr 0.752198 | ppl 4.96 | wps 38852.4 | wpb 21803.6 | bsz 252.6 | num_updates 1307 (progress_bar.py:269, print())
[2021-04-04 05:09:20]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt (epoch 1 @ 1307 updates, score 0.752198) (writing took 0.956630 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:10:26]    INFO >> epoch 002:    193 / 1307 loss=2.218, accuracy=0, mrr=0, ppl=4.65, wps=33206.2, ups=2.73, wpb=12150.1, bsz=128, num_updates=1500, lr=0.001, gnorm=0.557, clip=0, train_wall=153, wall=501 (progress_bar.py:260, log())
[2021-04-04 05:12:58]    INFO >> epoch 002:    693 / 1307 loss=1.966, accuracy=0, mrr=0, ppl=3.91, wps=39822.6, ups=3.3, wpb=12065.3, bsz=128, num_updates=2000, lr=0.001, gnorm=0.494, clip=0, train_wall=150, wall=652 (progress_bar.py:260, log())
[2021-04-04 05:15:29]    INFO >> epoch 002:   1193 / 1307 loss=1.816, accuracy=0, mrr=0, ppl=3.52, wps=40072.7, ups=3.3, wpb=12125.6, bsz=128, num_updates=2500, lr=0.001, gnorm=0.462, clip=0, train_wall=150, wall=804 (progress_bar.py:260, log())
[2021-04-04 05:16:04]    INFO >> epoch 002 | loss 1.913 | accuracy 0 | mrr 0 | ppl 3.77 | wps 37091.3 | ups 3.06 | wpb 12113.3 | bsz 128 | num_updates 2614 | lr 0.001 | gnorm 0.484 | clip 0 | train_wall 395 | wall 839 (progress_bar.py:269, print())
[2021-04-04 05:16:21]    INFO >> epoch 002 | valid on 'valid' subset | loss 2.015 | accuracy 0.695934 | mrr 0.780411 | ppl 4.04 | wps 57107.3 | wpb 21803.6 | bsz 252.6 | num_updates 2614 | best_mrr 0.780411 (progress_bar.py:269, print())
[2021-04-04 05:16:36]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt (epoch 2 @ 2614 updates, score 0.780411) (writing took 14.463011 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:18:40]    INFO >> epoch 003:    386 / 1307 loss=1.708, accuracy=0, mrr=0, ppl=3.27, wps=31736.1, ups=2.61, wpb=12137.2, bsz=128, num_updates=3000, lr=0.001, gnorm=0.436, clip=0, train_wall=153, wall=995 (progress_bar.py:260, log())
[2021-04-04 05:21:11]    INFO >> epoch 003:    886 / 1307 loss=1.635, accuracy=0, mrr=0, ppl=3.11, wps=40088, ups=3.32, wpb=12090.5, bsz=128, num_updates=3500, lr=0.001, gnorm=0.417, clip=0, train_wall=150, wall=1146 (progress_bar.py:260, log())
[2021-04-04 05:23:18]    INFO >> epoch 003 | loss 1.636 | accuracy 0 | mrr 0 | ppl 3.11 | wps 36490.9 | ups 3.01 | wpb 12113.3 | bsz 128 | num_updates 3921 | lr 0.001 | gnorm 0.419 | clip 0 | train_wall 393 | wall 1273 (progress_bar.py:269, print())
[2021-04-04 05:23:35]    INFO >> epoch 003 | valid on 'valid' subset | loss 1.943 | accuracy 0.707626 | mrr 0.789036 | ppl 3.85 | wps 57049.9 | wpb 21803.6 | bsz 252.6 | num_updates 3921 | best_mrr 0.789036 (progress_bar.py:269, print())
[2021-04-04 05:23:50]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt (epoch 3 @ 3921 updates, score 0.789036) (writing took 14.787927 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:24:20]    INFO >> epoch 004:     79 / 1307 loss=1.578, accuracy=0, mrr=0, ppl=2.98, wps=32086, ups=2.65, wpb=12095.2, bsz=128, num_updates=4000, lr=0.001, gnorm=0.406, clip=0, train_wall=149, wall=1334 (progress_bar.py:260, log())
[2021-04-04 05:26:53]    INFO >> epoch 004:    579 / 1307 loss=1.524, accuracy=0, mrr=0, ppl=2.88, wps=39493.9, ups=3.26, wpb=12115.2, bsz=128, num_updates=4500, lr=0.001, gnorm=0.396, clip=0, train_wall=152, wall=1487 (progress_bar.py:260, log())
[2021-04-04 05:29:24]    INFO >> epoch 004:   1079 / 1307 loss=1.487, accuracy=0, mrr=0, ppl=2.8, wps=40119.1, ups=3.31, wpb=12137.6, bsz=128, num_updates=5000, lr=0.001, gnorm=0.382, clip=0, train_wall=150, wall=1639 (progress_bar.py:260, log())
[2021-04-04 05:30:33]    INFO >> epoch 004 | loss 1.5 | accuracy 0 | mrr 0 | ppl 2.83 | wps 36376.5 | ups 3 | wpb 12113.3 | bsz 128 | num_updates 5228 | lr 0.001 | gnorm 0.388 | clip 0 | train_wall 394 | wall 1708 (progress_bar.py:269, print())
[2021-04-04 05:30:50]    INFO >> epoch 004 | valid on 'valid' subset | loss 1.923 | accuracy 0.71071 | mrr 0.791463 | ppl 3.79 | wps 56442.4 | wpb 21803.6 | bsz 252.6 | num_updates 5228 | best_mrr 0.791463 (progress_bar.py:269, print())
[2021-04-04 05:31:05]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt (epoch 4 @ 5228 updates, score 0.791463) (writing took 14.460092 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:32:34]    INFO >> epoch 005:    272 / 1307 loss=1.449, accuracy=0, mrr=0, ppl=2.73, wps=31922, ups=2.63, wpb=12126.5, bsz=128, num_updates=5500, lr=0.001, gnorm=0.378, clip=0, train_wall=151, wall=1829 (progress_bar.py:260, log())
[2021-04-04 05:35:04]    INFO >> epoch 005:    772 / 1307 loss=1.416, accuracy=0, mrr=0, ppl=2.67, wps=40248.3, ups=3.33, wpb=12088.6, bsz=128, num_updates=6000, lr=0.001, gnorm=0.363, clip=0, train_wall=149, wall=1979 (progress_bar.py:260, log())
[2021-04-04 05:37:35]    INFO >> epoch 005:   1272 / 1307 loss=1.389, accuracy=0, mrr=0, ppl=2.62, wps=40275.7, ups=3.32, wpb=12128.1, bsz=128, num_updates=6500, lr=0.001, gnorm=0.364, clip=0, train_wall=150, wall=2129 (progress_bar.py:260, log())
[2021-04-04 05:37:46]    INFO >> epoch 005 | loss 1.41 | accuracy 0 | mrr 0 | ppl 2.66 | wps 36614.3 | ups 3.02 | wpb 12113.3 | bsz 128 | num_updates 6535 | lr 0.001 | gnorm 0.367 | clip 0 | train_wall 392 | wall 2140 (progress_bar.py:269, print())
[2021-04-04 05:38:03]    INFO >> epoch 005 | valid on 'valid' subset | loss 1.921 | accuracy 0.713361 | mrr 0.793277 | ppl 3.79 | wps 57876 | wpb 21803.6 | bsz 252.6 | num_updates 6535 | best_mrr 0.793277 (progress_bar.py:269, print())
[2021-04-04 05:38:17]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt (epoch 5 @ 6535 updates, score 0.793277) (writing took 14.662508 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:40:43]    INFO >> epoch 006:    465 / 1307 loss=1.339, accuracy=0, mrr=0, ppl=2.53, wps=32220.5, ups=2.66, wpb=12095.3, bsz=128, num_updates=7000, lr=0.001, gnorm=0.335, clip=0, train_wall=149, wall=2317 (progress_bar.py:260, log())
[2021-04-04 05:43:14]    INFO >> epoch 006:    965 / 1307 loss=1.354, accuracy=0, mrr=0, ppl=2.56, wps=39893.1, ups=3.3, wpb=12093.9, bsz=128, num_updates=7500, lr=0.001, gnorm=0.326, clip=0, train_wall=150, wall=2469 (progress_bar.py:260, log())
[2021-04-04 05:44:57]    INFO >> epoch 006 | loss 1.349 | accuracy 0 | mrr 0 | ppl 2.55 | wps 36705.8 | ups 3.03 | wpb 12113.3 | bsz 128 | num_updates 7842 | lr 0.001 | gnorm 0.327 | clip 0 | train_wall 391 | wall 2572 (progress_bar.py:269, print())
[2021-04-04 05:45:14]    INFO >> epoch 006 | valid on 'valid' subset | loss 1.864 | accuracy 0.721455 | mrr 0.799525 | ppl 3.64 | wps 57485.5 | wpb 21803.6 | bsz 252.6 | num_updates 7842 | best_mrr 0.799525 (progress_bar.py:269, print())
[2021-04-04 05:45:28]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_best.pt (epoch 6 @ 7842 updates, score 0.799525) (writing took 14.424774 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:46:22]    INFO >> epoch 007:    158 / 1307 loss=1.324, accuracy=0, mrr=0, ppl=2.5, wps=32339.2, ups=2.66, wpb=12163.8, bsz=128, num_updates=8000, lr=0.001, gnorm=0.321, clip=0, train_wall=150, wall=2657 (progress_bar.py:260, log())
[2021-04-04 05:48:53]    INFO >> epoch 007:    658 / 1307 loss=1.275, accuracy=0, mrr=0, ppl=2.42, wps=40034.9, ups=3.31, wpb=12097.2, bsz=128, num_updates=8500, lr=0.001, gnorm=0.325, clip=0, train_wall=150, wall=2808 (progress_bar.py:260, log())
[2021-04-04 05:51:25]    INFO >> epoch 007:   1158 / 1307 loss=1.298, accuracy=0, mrr=0, ppl=2.46, wps=39961.3, ups=3.3, wpb=12100.1, bsz=128, num_updates=9000, lr=0.001, gnorm=0.313, clip=0, train_wall=150, wall=2959 (progress_bar.py:260, log())
[2021-04-04 05:52:10]    INFO >> epoch 007 | loss 1.283 | accuracy 0 | mrr 0 | ppl 2.43 | wps 36551 | ups 3.02 | wpb 12113.3 | bsz 128 | num_updates 9149 | lr 0.001 | gnorm 0.318 | clip 0 | train_wall 393 | wall 3005 (progress_bar.py:269, print())
[2021-04-04 05:52:27]    INFO >> epoch 007 | valid on 'valid' subset | loss 1.878 | accuracy 0.721053 | mrr 0.799095 | ppl 3.68 | wps 56978 | wpb 21803.6 | bsz 252.6 | num_updates 9149 | best_mrr 0.799525 (progress_bar.py:269, print())
[2021-04-04 05:52:35]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_last.pt (epoch 7 @ 9149 updates, score 0.799095) (writing took 7.877657 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 05:54:26]    INFO >> epoch 008:    351 / 1307 loss=1.231, accuracy=0, mrr=0, ppl=2.35, wps=33384.2, ups=2.76, wpb=12084.2, bsz=128, num_updates=9500, lr=0.001, gnorm=0.313, clip=0, train_wall=149, wall=3140 (progress_bar.py:260, log())
[2021-04-04 05:56:58]    INFO >> epoch 008:    851 / 1307 loss=1.233, accuracy=0, mrr=0, ppl=2.35, wps=39811.5, ups=3.28, wpb=12154.7, bsz=128, num_updates=10000, lr=0.001, gnorm=0.314, clip=0, train_wall=152, wall=3293 (progress_bar.py:260, log())
[2021-04-04 05:59:17]    INFO >> epoch 008 | loss 1.23 | accuracy 0 | mrr 0 | ppl 2.35 | wps 37135 | ups 3.07 | wpb 12113.3 | bsz 128 | num_updates 10456 | lr 0.001 | gnorm 0.31 | clip 0 | train_wall 392 | wall 3431 (progress_bar.py:269, print())
[2021-04-04 05:59:33]    INFO >> epoch 008 | valid on 'valid' subset | loss 1.887 | accuracy 0.72122 | mrr 0.799259 | ppl 3.7 | wps 57685.4 | wpb 21803.6 | bsz 252.6 | num_updates 10456 | best_mrr 0.799525 (progress_bar.py:269, print())
[2021-04-04 05:59:41]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_last.pt (epoch 8 @ 10456 updates, score 0.799259) (writing took 7.727527 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:00:00]    INFO >> epoch 009:     44 / 1307 loss=1.237, accuracy=0, mrr=0, ppl=2.36, wps=33251.5, ups=2.75, wpb=12092.2, bsz=128, num_updates=10500, lr=0.001, gnorm=0.303, clip=0, train_wall=150, wall=3475 (progress_bar.py:260, log())
[2021-04-04 06:02:32]    INFO >> epoch 009:    544 / 1307 loss=1.165, accuracy=0, mrr=0, ppl=2.24, wps=40036, ups=3.3, wpb=12149.8, bsz=128, num_updates=11000, lr=0.001, gnorm=0.308, clip=0, train_wall=151, wall=3626 (progress_bar.py:260, log())
[2021-04-04 06:05:03]    INFO >> epoch 009:   1044 / 1307 loss=1.192, accuracy=0, mrr=0, ppl=2.28, wps=40082.4, ups=3.31, wpb=12113.6, bsz=128, num_updates=11500, lr=0.001, gnorm=0.302, clip=0, train_wall=150, wall=3778 (progress_bar.py:260, log())
[2021-04-04 06:06:24]    INFO >> epoch 009 | loss 1.183 | accuracy 0 | mrr 0 | ppl 2.27 | wps 37089.8 | ups 3.06 | wpb 12113.3 | bsz 128 | num_updates 11763 | lr 0.001 | gnorm 0.303 | clip 0 | train_wall 393 | wall 3858 (progress_bar.py:269, print())
[2021-04-04 06:06:40]    INFO >> epoch 009 | valid on 'valid' subset | loss 1.919 | accuracy 0.72145 | mrr 0.798601 | ppl 3.78 | wps 56914.8 | wpb 21803.6 | bsz 252.6 | num_updates 11763 | best_mrr 0.799525 (progress_bar.py:269, print())
[2021-04-04 06:06:48]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_last.pt (epoch 9 @ 11763 updates, score 0.798601) (writing took 7.937165 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:08:05]    INFO >> epoch 010:    237 / 1307 loss=1.156, accuracy=0, mrr=0, ppl=2.23, wps=33144.7, ups=2.75, wpb=12060.8, bsz=128, num_updates=12000, lr=0.001, gnorm=0.302, clip=0, train_wall=150, wall=3960 (progress_bar.py:260, log())
[2021-04-04 06:10:37]    INFO >> epoch 010:    737 / 1307 loss=1.14, accuracy=0, mrr=0, ppl=2.2, wps=39870.5, ups=3.29, wpb=12102.5, bsz=128, num_updates=12500, lr=0.001, gnorm=0.308, clip=0, train_wall=151, wall=4111 (progress_bar.py:260, log())
[2021-04-04 06:13:09]    INFO >> epoch 010:   1237 / 1307 loss=1.161, accuracy=0, mrr=0, ppl=2.24, wps=40009.7, ups=3.29, wpb=12155.9, bsz=128, num_updates=13000, lr=0.001, gnorm=0.298, clip=0, train_wall=151, wall=4263 (progress_bar.py:260, log())
[2021-04-04 06:13:30]    INFO >> epoch 010 | loss 1.141 | accuracy 0 | mrr 0 | ppl 2.21 | wps 37112.6 | ups 3.06 | wpb 12113.3 | bsz 128 | num_updates 13070 | lr 0.001 | gnorm 0.303 | clip 0 | train_wall 393 | wall 4285 (progress_bar.py:269, print())
[2021-04-04 06:13:47]    INFO >> epoch 010 | valid on 'valid' subset | loss 1.943 | accuracy 0.721781 | mrr 0.798677 | ppl 3.84 | wps 57456.4 | wpb 21803.6 | bsz 252.6 | num_updates 13070 | best_mrr 0.799525 (progress_bar.py:269, print())
[2021-04-04 06:13:55]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_last.pt (epoch 10 @ 13070 updates, score 0.798677) (writing took 7.701338 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:16:10]    INFO >> epoch 011:    430 / 1307 loss=1.085, accuracy=0, mrr=0, ppl=2.12, wps=33447.9, ups=2.76, wpb=12103.9, bsz=128, num_updates=13500, lr=0.001, gnorm=0.305, clip=0, train_wall=149, wall=4444 (progress_bar.py:260, log())
[2021-04-04 06:18:39]    INFO >> epoch 011:    930 / 1307 loss=1.108, accuracy=0, mrr=0, ppl=2.16, wps=40564.9, ups=3.34, wpb=12144.8, bsz=128, num_updates=14000, lr=0.001, gnorm=0.297, clip=0, train_wall=149, wall=4594 (progress_bar.py:260, log())
[2021-04-04 06:20:34]    INFO >> epoch 011 | loss 1.101 | accuracy 0 | mrr 0 | ppl 2.15 | wps 37356.9 | ups 3.08 | wpb 12113.3 | bsz 128 | num_updates 14377 | lr 0.001 | gnorm 0.299 | clip 0 | train_wall 390 | wall 4708 (progress_bar.py:269, print())
[2021-04-04 06:20:51]    INFO >> epoch 011 | valid on 'valid' subset | loss 1.966 | accuracy 0.718868 | mrr 0.796368 | ppl 3.91 | wps 57306.2 | wpb 21803.6 | bsz 252.6 | num_updates 14377 | best_mrr 0.799525 (progress_bar.py:269, print())
[2021-04-04 06:20:59]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/go/gpt2/checkpoints/checkpoint_last.pt (epoch 11 @ 14377 updates, score 0.796368) (writing took 7.995179 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 06:20:59]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:176, should_stop_early())
[2021-04-04 06:20:59]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:259, single_main())
[2021-04-04 06:20:59]    INFO >> done training in 4732.5 seconds (train.py:271, single_main())
