nohup: ignoring input
[2021-04-04 13:06:39]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/completion/gpt2/config/csn_feng/javascript.yml (train.py:291, cli_main())
[2021-04-04 13:06:39]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:293, cli_main())
[2021-04-04 13:06:41]    INFO >> distributed init (rank 2): tcp://localhost:16240 (distributed_utils.py:84, distributed_init())
[2021-04-04 13:06:41]    INFO >> distributed init (rank 1): tcp://localhost:16240 (distributed_utils.py:84, distributed_init())
[2021-04-04 13:06:41]    INFO >> distributed init (rank 0): tcp://localhost:16240 (distributed_utils.py:84, distributed_init())
[2021-04-04 13:06:41]    INFO >> distributed init (rank 3): tcp://localhost:16240 (distributed_utils.py:84, distributed_init())
[2021-04-04 13:06:41]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 13:06:42]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 13:06:42]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 13:06:42]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-04-04 13:06:42]    INFO >> initialized host node14 as rank 0 (distributed_utils.py:93, distributed_init())
[2021-04-04 13:06:42]    INFO >> initialized host node14 as rank 1 (distributed_utils.py:93, distributed_init())
[2021-04-04 13:06:42]    INFO >> initialized host node14 as rank 2 (distributed_utils.py:93, distributed_init())
[2021-04-04 13:06:42]    INFO >> initialized host node14 as rank 3 (distributed_utils.py:93, distributed_init())
[2021-04-04 13:06:48]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 64, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16240', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript', 'target_lang': 'code_tokens', 'max_target_positions': 513, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 513, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}} (train.py:201, single_main())
[2021-04-04 13:06:48]    INFO >> [code_tokens] dictionary: 50000 types (completion.py:101, setup_task())
[2021-04-04 13:06:48]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 13:06:48]    INFO >> loaded 3885 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/valid.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 13:06:49]    INFO >> GPT2(
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50000, 300, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (1): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (2): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (3): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (4): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (5): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
    )
    (out_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
  )
) (train.py:212, single_main())
[2021-04-04 13:06:49]    INFO >> model completion_gpt2, criterion CompletionCrossEntropyCriterion (train.py:213, single_main())
[2021-04-04 13:06:49]    INFO >> num. model params: 23076864 (num. trained: 23076864) (train.py:214, single_main())
[2021-04-04 13:06:49]    INFO >> training on 4 GPUs (train.py:221, single_main())
[2021-04-04 13:06:49]    INFO >> max tokens per GPU = 100000.0 and max sentences per GPU = 32 (train.py:222, single_main())
[2021-04-04 13:06:49]    INFO >> no existing checkpoint found checkpoint_best.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-04 13:06:49]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-04-04 13:06:49]    INFO >> Truncate dataset into max length: 513 (completion.py:41, load_token_dataset())
[2021-04-04 13:06:49]    INFO >> loaded 58025 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/train.code_tokens (completion.py:42, load_token_dataset())
[2021-04-04 13:06:49]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 13:09:23]    INFO >> epoch 001 | loss 4.583 | accuracy 0 | mrr 0 | ppl 23.97 | wps 43735.7 | ups 3.08 | wpb 14224.5 | bsz 127.8 | num_updates 454 | lr 0.001 | gnorm 0.902 | clip 0 | train_wall 147 | wall 155 (progress_bar.py:269, print())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-04-04 13:09:39]    INFO >> epoch 001 | valid on 'valid' subset | loss 3.656 | accuracy 0.503169 | mrr 0.618793 | ppl 12.61 | wps 47374 | wpb 26884.2 | bsz 242.8 | num_updates 454 (progress_bar.py:269, print())
[2021-04-04 13:09:40]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 1 @ 454 updates, score 0.618793) (writing took 0.972800 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:10:00]    INFO >> epoch 002:     46 / 454 loss=4.485, accuracy=0, mrr=0, ppl=22.39, wps=38552.2, ups=2.71, wpb=14223.7, bsz=127.8, num_updates=500, lr=0.001, gnorm=0.895, clip=0, train_wall=161, wall=191 (progress_bar.py:260, log())
[2021-04-04 13:12:08]    INFO >> epoch 002 | loss 3.136 | accuracy 0 | mrr 0 | ppl 8.79 | wps 39220.5 | ups 2.76 | wpb 14224.5 | bsz 127.8 | num_updates 908 | lr 0.001 | gnorm 0.735 | clip 0 | train_wall 141 | wall 319 (progress_bar.py:269, print())
[2021-04-04 13:12:21]    INFO >> epoch 002 | valid on 'valid' subset | loss 3.007 | accuracy 0.562499 | mrr 0.674114 | ppl 8.04 | wps 64281.8 | wpb 26884.2 | bsz 242.8 | num_updates 908 | best_mrr 0.674114 (progress_bar.py:269, print())
[2021-04-04 13:12:35]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 2 @ 908 updates, score 0.674114) (writing took 14.388545 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:13:10]    INFO >> epoch 003:     92 / 454 loss=3.031, accuracy=0, mrr=0, ppl=8.18, wps=37447.5, ups=2.63, wpb=14251.5, bsz=127.8, num_updates=1000, lr=0.001, gnorm=0.717, clip=0, train_wall=156, wall=382 (progress_bar.py:260, log())
[2021-04-04 13:15:03]    INFO >> epoch 003 | loss 2.586 | accuracy 0 | mrr 0 | ppl 6.01 | wps 36863.8 | ups 2.59 | wpb 14224.5 | bsz 127.8 | num_updates 1362 | lr 0.001 | gnorm 0.65 | clip 0 | train_wall 141 | wall 495 (progress_bar.py:269, print())
[2021-04-04 13:15:16]    INFO >> epoch 003 | valid on 'valid' subset | loss 2.788 | accuracy 0.584806 | mrr 0.693931 | ppl 6.9 | wps 66180.3 | wpb 26884.2 | bsz 242.8 | num_updates 1362 | best_mrr 0.693931 (progress_bar.py:269, print())
[2021-04-04 13:15:30]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 3 @ 1362 updates, score 0.693931) (writing took 14.393650 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:16:19]    INFO >> epoch 004:    138 / 454 loss=2.5, accuracy=0, mrr=0, ppl=5.66, wps=37725.9, ups=2.65, wpb=14238.5, bsz=127.8, num_updates=1500, lr=0.001, gnorm=0.646, clip=0, train_wall=154, wall=570 (progress_bar.py:260, log())
[2021-04-04 13:17:58]    INFO >> epoch 004 | loss 2.307 | accuracy 0 | mrr 0 | ppl 4.95 | wps 36978 | ups 2.6 | wpb 14224.5 | bsz 127.8 | num_updates 1816 | lr 0.001 | gnorm 0.629 | clip 0 | train_wall 140 | wall 669 (progress_bar.py:269, print())
[2021-04-04 13:18:10]    INFO >> epoch 004 | valid on 'valid' subset | loss 2.715 | accuracy 0.59314 | mrr 0.700875 | ppl 6.57 | wps 66693.9 | wpb 26884.2 | bsz 242.8 | num_updates 1816 | best_mrr 0.700875 (progress_bar.py:269, print())
[2021-04-04 13:18:25]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 4 @ 1816 updates, score 0.700875) (writing took 14.460846 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:19:28]    INFO >> epoch 005:    184 / 454 loss=2.238, accuracy=0, mrr=0, ppl=4.72, wps=37664.9, ups=2.65, wpb=14224.9, bsz=127.8, num_updates=2000, lr=0.001, gnorm=0.613, clip=0, train_wall=154, wall=759 (progress_bar.py:260, log())
[2021-04-04 13:20:52]    INFO >> epoch 005 | loss 2.136 | accuracy 0 | mrr 0 | ppl 4.4 | wps 37045.8 | ups 2.6 | wpb 14224.5 | bsz 127.8 | num_updates 2270 | lr 0.001 | gnorm 0.595 | clip 0 | train_wall 140 | wall 843 (progress_bar.py:269, print())
[2021-04-04 13:21:05]    INFO >> epoch 005 | valid on 'valid' subset | loss 2.656 | accuracy 0.601644 | mrr 0.707978 | ppl 6.3 | wps 64328.3 | wpb 26884.2 | bsz 242.8 | num_updates 2270 | best_mrr 0.707978 (progress_bar.py:269, print())
[2021-04-04 13:21:19]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 5 @ 2270 updates, score 0.707978) (writing took 14.285034 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:22:36]    INFO >> epoch 006:    230 / 454 loss=2.056, accuracy=0, mrr=0, ppl=4.16, wps=37770.2, ups=2.66, wpb=14214.8, bsz=127.8, num_updates=2500, lr=0.001, gnorm=0.551, clip=0, train_wall=154, wall=947 (progress_bar.py:260, log())
[2021-04-04 13:23:47]    INFO >> epoch 006 | loss 2.007 | accuracy 0 | mrr 0 | ppl 4.02 | wps 37017.5 | ups 2.6 | wpb 14224.5 | bsz 127.8 | num_updates 2724 | lr 0.001 | gnorm 0.516 | clip 0 | train_wall 140 | wall 1018 (progress_bar.py:269, print())
[2021-04-04 13:23:59]    INFO >> epoch 006 | valid on 'valid' subset | loss 2.567 | accuracy 0.612192 | mrr 0.717198 | ppl 5.93 | wps 64889.9 | wpb 26884.2 | bsz 242.8 | num_updates 2724 | best_mrr 0.717198 (progress_bar.py:269, print())
[2021-04-04 13:24:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 6 @ 2724 updates, score 0.717198) (writing took 14.616949 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:25:46]    INFO >> epoch 007:    276 / 454 loss=1.942, accuracy=0, mrr=0, ppl=3.84, wps=37339.3, ups=2.63, wpb=14184.1, bsz=127.8, num_updates=3000, lr=0.001, gnorm=0.521, clip=0, train_wall=155, wall=1137 (progress_bar.py:260, log())
[2021-04-04 13:26:42]    INFO >> epoch 007 | loss 1.897 | accuracy 0 | mrr 0 | ppl 3.72 | wps 36837.3 | ups 2.59 | wpb 14224.5 | bsz 127.8 | num_updates 3178 | lr 0.001 | gnorm 0.518 | clip 0 | train_wall 141 | wall 1193 (progress_bar.py:269, print())
[2021-04-04 13:26:54]    INFO >> epoch 007 | valid on 'valid' subset | loss 2.565 | accuracy 0.615923 | mrr 0.719784 | ppl 5.92 | wps 66045 | wpb 26884.2 | bsz 242.8 | num_updates 3178 | best_mrr 0.719784 (progress_bar.py:269, print())
[2021-04-04 13:27:09]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 7 @ 3178 updates, score 0.719784) (writing took 14.955631 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:28:54]    INFO >> epoch 008:    322 / 454 loss=1.84, accuracy=0, mrr=0, ppl=3.58, wps=37893.1, ups=2.66, wpb=14219.1, bsz=127.8, num_updates=3500, lr=0.001, gnorm=0.521, clip=0, train_wall=153, wall=1325 (progress_bar.py:260, log())
[2021-04-04 13:29:36]    INFO >> epoch 008 | loss 1.81 | accuracy 0 | mrr 0 | ppl 3.51 | wps 37146 | ups 2.61 | wpb 14224.5 | bsz 127.8 | num_updates 3632 | lr 0.001 | gnorm 0.522 | clip 0 | train_wall 139 | wall 1367 (progress_bar.py:269, print())
[2021-04-04 13:29:48]    INFO >> epoch 008 | valid on 'valid' subset | loss 2.578 | accuracy 0.616127 | mrr 0.719666 | ppl 5.97 | wps 64564.2 | wpb 26884.2 | bsz 242.8 | num_updates 3632 | best_mrr 0.719784 (progress_bar.py:269, print())
[2021-04-04 13:29:56]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_last.pt (epoch 8 @ 3632 updates, score 0.719666) (writing took 7.732077 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:31:57]    INFO >> epoch 009:    368 / 454 loss=1.757, accuracy=0, mrr=0, ppl=3.38, wps=39006.3, ups=2.73, wpb=14263.8, bsz=127.8, num_updates=4000, lr=0.001, gnorm=0.521, clip=0, train_wall=155, wall=1508 (progress_bar.py:260, log())
[2021-04-04 13:32:24]    INFO >> epoch 009 | loss 1.733 | accuracy 0 | mrr 0 | ppl 3.32 | wps 38449.4 | ups 2.7 | wpb 14224.5 | bsz 127.8 | num_updates 4086 | lr 0.001 | gnorm 0.518 | clip 0 | train_wall 140 | wall 1535 (progress_bar.py:269, print())
[2021-04-04 13:32:36]    INFO >> epoch 009 | valid on 'valid' subset | loss 2.603 | accuracy 0.617036 | mrr 0.719931 | ppl 6.07 | wps 64929.8 | wpb 26884.2 | bsz 242.8 | num_updates 4086 | best_mrr 0.719931 (progress_bar.py:269, print())
[2021-04-04 13:32:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 9 @ 4086 updates, score 0.719931) (writing took 14.505307 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:35:06]    INFO >> epoch 010:    414 / 454 loss=1.676, accuracy=0, mrr=0, ppl=3.2, wps=37514.7, ups=2.64, wpb=14199.7, bsz=127.8, num_updates=4500, lr=0.001, gnorm=0.522, clip=0, train_wall=155, wall=1697 (progress_bar.py:260, log())
[2021-04-04 13:35:18]    INFO >> epoch 010 | loss 1.662 | accuracy 0 | mrr 0 | ppl 3.17 | wps 36976.1 | ups 2.6 | wpb 14224.5 | bsz 127.8 | num_updates 4540 | lr 0.001 | gnorm 0.526 | clip 0 | train_wall 140 | wall 1710 (progress_bar.py:269, print())
[2021-04-04 13:35:31]    INFO >> epoch 010 | valid on 'valid' subset | loss 2.627 | accuracy 0.618248 | mrr 0.720325 | ppl 6.18 | wps 65360.7 | wpb 26884.2 | bsz 242.8 | num_updates 4540 | best_mrr 0.720325 (progress_bar.py:269, print())
[2021-04-04 13:35:45]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_best.pt (epoch 10 @ 4540 updates, score 0.720325) (writing took 14.326912 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:38:14]    INFO >> epoch 011 | loss 1.594 | accuracy 0 | mrr 0 | ppl 3.02 | wps 36849.3 | ups 2.59 | wpb 14224.5 | bsz 127.8 | num_updates 4994 | lr 0.001 | gnorm 0.52 | clip 0 | train_wall 141 | wall 1885 (progress_bar.py:269, print())
[2021-04-04 13:38:26]    INFO >> epoch 011 | valid on 'valid' subset | loss 2.674 | accuracy 0.614988 | mrr 0.717588 | ppl 6.38 | wps 64805.3 | wpb 26884.2 | bsz 242.8 | num_updates 4994 | best_mrr 0.720325 (progress_bar.py:269, print())
[2021-04-04 13:38:34]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_last.pt (epoch 11 @ 4994 updates, score 0.717588) (writing took 8.135273 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:38:42]    INFO >> epoch 012:      6 / 454 loss=1.601, accuracy=0, mrr=0, ppl=3.03, wps=32871.3, ups=2.31, wpb=14226.8, bsz=127.7, num_updates=5000, lr=0.001, gnorm=0.521, clip=0, train_wall=155, wall=1913 (progress_bar.py:260, log())
[2021-04-04 13:41:03]    INFO >> epoch 012 | loss 1.533 | accuracy 0 | mrr 0 | ppl 2.89 | wps 38127.9 | ups 2.68 | wpb 14224.5 | bsz 127.8 | num_updates 5448 | lr 0.001 | gnorm 0.538 | clip 0 | train_wall 141 | wall 2054 (progress_bar.py:269, print())
[2021-04-04 13:41:15]    INFO >> epoch 012 | valid on 'valid' subset | loss 2.719 | accuracy 0.61208 | mrr 0.71562 | ppl 6.59 | wps 64952.7 | wpb 26884.2 | bsz 242.8 | num_updates 5448 | best_mrr 0.720325 (progress_bar.py:269, print())
[2021-04-04 13:41:23]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_last.pt (epoch 12 @ 5448 updates, score 0.71562) (writing took 7.875244 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:41:45]    INFO >> epoch 013:     52 / 454 loss=1.52, accuracy=0, mrr=0, ppl=2.87, wps=38982.1, ups=2.74, wpb=14235, bsz=127.8, num_updates=5500, lr=0.001, gnorm=0.539, clip=0, train_wall=155, wall=2096 (progress_bar.py:260, log())
[2021-04-04 13:43:52]    INFO >> epoch 013 | loss 1.473 | accuracy 0 | mrr 0 | ppl 2.78 | wps 38199.2 | ups 2.69 | wpb 14224.5 | bsz 127.8 | num_updates 5902 | lr 0.001 | gnorm 0.541 | clip 0 | train_wall 141 | wall 2223 (progress_bar.py:269, print())
[2021-04-04 13:44:05]    INFO >> epoch 013 | valid on 'valid' subset | loss 2.778 | accuracy 0.610887 | mrr 0.713092 | ppl 6.86 | wps 65449.2 | wpb 26884.2 | bsz 242.8 | num_updates 5902 | best_mrr 0.720325 (progress_bar.py:269, print())
[2021-04-04 13:44:12]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_last.pt (epoch 13 @ 5902 updates, score 0.713092) (writing took 7.720659 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:44:48]    INFO >> epoch 014:     98 / 454 loss=1.458, accuracy=0, mrr=0, ppl=2.75, wps=38718.9, ups=2.72, wpb=14225.6, bsz=127.8, num_updates=6000, lr=0.001, gnorm=0.539, clip=0, train_wall=156, wall=2280 (progress_bar.py:260, log())
[2021-04-04 13:46:41]    INFO >> epoch 014 | loss 1.415 | accuracy 0 | mrr 0 | ppl 2.67 | wps 38333.4 | ups 2.69 | wpb 14224.5 | bsz 127.8 | num_updates 6356 | lr 0.001 | gnorm 0.542 | clip 0 | train_wall 141 | wall 2392 (progress_bar.py:269, print())
[2021-04-04 13:46:53]    INFO >> epoch 014 | valid on 'valid' subset | loss 2.831 | accuracy 0.608437 | mrr 0.711126 | ppl 7.11 | wps 64159.6 | wpb 26884.2 | bsz 242.8 | num_updates 6356 | best_mrr 0.720325 (progress_bar.py:269, print())
[2021-04-04 13:47:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_last.pt (epoch 14 @ 6356 updates, score 0.711126) (writing took 7.708304 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:47:53]    INFO >> epoch 015:    144 / 454 loss=1.396, accuracy=0, mrr=0, ppl=2.63, wps=38529.2, ups=2.71, wpb=14208, bsz=127.8, num_updates=6500, lr=0.001, gnorm=0.546, clip=0, train_wall=157, wall=2464 (progress_bar.py:260, log())
[2021-04-04 13:49:30]    INFO >> epoch 015 | loss 1.362 | accuracy 0 | mrr 0 | ppl 2.57 | wps 38198 | ups 2.69 | wpb 14224.5 | bsz 127.8 | num_updates 6810 | lr 0.001 | gnorm 0.552 | clip 0 | train_wall 141 | wall 2561 (progress_bar.py:269, print())
[2021-04-04 13:49:43]    INFO >> epoch 015 | valid on 'valid' subset | loss 2.889 | accuracy 0.607642 | mrr 0.709702 | ppl 7.41 | wps 60405.4 | wpb 26884.2 | bsz 242.8 | num_updates 6810 | best_mrr 0.720325 (progress_bar.py:269, print())
[2021-04-04 13:49:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/javascript/gpt2/checkpoints/checkpoint_last.pt (epoch 15 @ 6810 updates, score 0.709702) (writing took 8.395283 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-04-04 13:49:51]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:176, should_stop_early())
[2021-04-04 13:49:51]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:259, single_main())
[2021-04-04 13:49:51]    INFO >> done training in 2582.1 seconds (train.py:271, single_main())
